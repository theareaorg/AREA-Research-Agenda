,Title,Description,Keywords,Categories,Stakeholders,Importance,Methdologies,Timeframes,Program,Miscellaneous,Author,History
0,Visualization of Data About or From Tools in AR Display,"Combining live sensor data and tools with AR displays enables many use cases. This topic studies how to meet requirements of Industrial Internet of Things (IIoT) use cases in new and intuitive ways. In the IIoT, and as part of Industry 4.0, machines and tools run software and may be connected to corporate infrastructure with cables or radios. Frequently, there are consoles on which a user receives tool status and diagnostics. Sensors may be integrated or attached to a tool, thereby enhancing the tool's capability. A tool without direct connection to enterprise IT may be detected with the AR system or paired with a user's AR device. Data from tools (or from a technician's AR system) may be sent to work order management systems, SCADA, and asset tracing and tool use or management systems (e.g., the torque on a screw needs to be increased or decreased).

When an AR-assisted user is controlling connected tools (or interacting with unconnected tools) to perform a task, they do not need to turn their attention away from the main task to receive useful information. However, it is critical that the information provided in AR does not interfere with the user's awareness of the tool and is of value to the user. There is the potential for back-end IIoT systems to contribute to the user's productivity by providing clear indicators of status.

This research topic explores and studies the usability of different approaches to visualize data from or about tools (that may be generated by a user's own device) in an IIoT context. The research could also include making, with AR device pairing, those tools without sensors or that are not connected, more detectable and/or intelligent. The user may also have the ability to receive and to see in their AR display assistance from a remote tool or system expert. The research can also examine integration of data from tools and users' devices with operational software to automatically track processes, apply quality control, and access recommendations for users and managers.

","connected tools, manufacturing, AR display, industrial Internet of Things (IIoT), SCADA, asset tracing, asset management, maintenance, diagnostics, usability, perception, real time sensor data, tools, Internet 4.0, smart tools, sensors, remote assistance, work instructions, interactive systems and tools, Internet of Things, sensors, manufacturing","Business, Technology, Use Cases, Industries","Operators of manufacturing, repair, maintenance facilities, quality managers, managers of factories, providers of repair and maintenance services, oil and gas, power and energy, medical practitioners, experience designers, enterprise IT, systems integrators specializing in IIoT or Industry 4.0","- AREA members with manufacturing facilities for assembly, or providing repair or maintenance services, or field services where complex, connected (or not ""smart"") tools are used need better ways to visualize data and to provide instantaneous status information to users.
- By immediately visualizing feedback about the status of a tool or process, the user will save time and perform the task or process to criteria the first time. However, the additional information provided must not interfere with performance of tasks and must be compliant with regulations.
- Assessment of technician sentiment toward the AR-connected tools (i.e. do experienced technicians feel they would need this and/or does it affect existing workflow?) could lead to improvements in design or introduction of AR.
- Increased understanding of operational improvements tied to connected tools could improve cost savings analysis and RoI calculations.","An experimental environment using a range of connected or smart tools and procedures will provide the suitable environment for this research. Users of Industrial Internet of Things (IIoT) or Industry 4.0 systems will perform tasks under controlled conditions. Motion and time studies, quality inspection and other measurements of performance will be used to quantify impacts. Users will complete surveys about satisfaction and feedback on various visualizations.",Medium,"This research topic is broad in scope. It can include exploring different approaches to visualize data about tools to better understand and document or compare usability. This would benefit the industry by establishing Industry 4.0 best practices or guidelines. The research could also include making, with AR device pairing, those tools without sensors or that are not connected, more detectable and/or intelligent. This would expand the types and number of existing tools that would be tracked, without the cost of replacing tools that were developed prior to Industry 4.0 adoption. It also can examine integration of data from tools and users' devices with operational software to automatically track processes and provide remote assistance, quality control and recommendations for users and managers. Further, this topic can be combined with studies of AR-enabled guidance, integration of AR with IoT, finding parts and supplies in a large space with AR, 3D user interfaces, live sensor visualization for other use cases, and other use cases in factory or field settings.","Two AREA members with financial support from both industry and government [MxD (in US), the Manufacturing Technology Center (MTC), and the AMRC (in UK)] have the required experimental environments and have already begun studying the approaches in this topic.

In December 2014, there was on https://www.plex.com/[the Plex web site] a blog post about the specific use case of a https://www.plex.com/blog/internet-making-things-connected-torque-wrench[connected torque wrench].",Christine Perey,2021-08-31
1,AR for Material Management and/or Supply Chain Flow with Work Orders,"Many industries track supply chains and juggle limited supplies of components, ingredients, or materials while planning work orders in a system. Combining data with AR displays could provide up-to-date information to users while on the job and assist in distributing human resources according to availability of materials. In the Industrial Internet of Things (IIoT), a facility or job site that is nearing the end of materials or has just received a shipment of materials can bring this status information into the AR-assisted user's field of view with updated work orders, reducing delays and optimizing use of resources and distribution of workers.

This topic explores how to better share information about materials, equipment, and tools tracked in operations management software, and, when there are mission critical updates, how to display to a user current information about materials. The user may receive a new work order, be warned about material shortages, or be notified of a new assignment to move materials between locations, for instance. In the latter use case, the user may receive AR-assisted navigation support.

When an AR-assisted user is made aware of status of materials in the supply chain, they are prepared to adapt and feel more satisfied. In addition, there is the potential for back-end IIoT systems to track the user's location before sending instructions with respect to material availabilities.

This research topic explores different approaches to communicating and visualizing levels of materials in an IIoT context to study usability and impacts on worker productivity and satisfaction. It also examines integration of data from connected pallets and packaging and users' devices with operational software to automatically track processes, check in/check out, and make recommendations for users and managers.

","logistics data processing, materials management, supply chain management, logistics, asset tracing, asset tracking, asset management, Industrial Internet of Things (IIoT), usability, perception, work orders, productivity, navigation, interactive systems and tools, Internet of Things, supply chain, time difference of arrival, warehouse automation, logistics data processing, pallets, supply chain management, manufacturing, mapping","Business, Technology, Use Cases, End User and User Experience","operators of manufacturing, repair, employees and technicians in manufacturing facilities or on sites where parts and materials are distributed, maintenance managers, quality managers, managers of factories, providers of repair and maintenance services, supply chain managers","- AREA members with manufacturing facilities for assembly, those providing repair or maintenance services, and those providing field services where materials must be combined with a worker's skills and availabilities need better ways to visualize data in situ and predict and plan work accordingly.
- Traditional ERP solutions for supply chain and work order management do not alert users to status updates in their visual field, so while they may provide real-time information, the technician must get information from other sources to act upon the change in status.
- AR systems connected to data processing for parts and supplies on a work site could provide instantaneous status information and guidance, and even navigation, to users.
- By immediately visualizing where materials are to be found and whether they are limited, the system will allow the user to waste less time waiting for materials and allow them to move parts or supplies to their optimal positions.","An experimental environment using a range of manufacturing conditions, materials, and procedures is the suitable environment for this research. Users of any tools or assembly systems located in facilities with limited ability to store local components will perform tasks under controlled conditions. Alerts will be introduced when supplies are nearly exhausted and when new shipments or orders arrive, along with other relevant real time information. Motion and time studies, quality inspection, and other measurements of performance will be used to quantify impacts. Users will complete surveys about satisfaction and feedback on various visualizations.",Medium,"This research topic can be combined with studies of AR-enabled guidance, 3D user interfaces, live sensor visualization for other use cases in factory and field settings, visualization of connected objects (e.g., tools), and IoT data streams.","Three non-commercial AREA members with financial support from both industry and government [MxD (in US), the Manufacturing Technology Center (The MTC, in UK) and the Advanced Manufacturing Research Center with Boeing (AMRC in UK)] have the required experimental environments and have already begun studying the approaches in this topic.",Christine Perey,2021-08-31
2,Dynamic Distribution of Sensing and Processing Capacity via Body-Area Networks,"Deploying enterprise AR solutions via head-mounted displays is inherently advantageous when simultaneous use of both hands is required. However, currently HMD performance is limited due to technological constraints, such as battery life and heat dissipation needs. One solution is to offload and distribute sensing and processing functions dynamically across other devices worn by the user (smartwatches, exoskeletons, sensing devices etc.)--that is, to a network of external wearable devices and resources.

A network of computing and sensing resources would not only decrease the display processing requirements, it would also enrich data feeds available in a complete AR system. A distributed architecture composed of haptic inputs, auditory signals, vibration and other sensors could provide richer data about the wearer (e.g. pose/posture of different body parts) and the environment. For example, using more diverse sensors could increase the system's ability to detect safety risks before they are clear to the user.

The inputs from more and more varied sensors should be studied for new opportunities. Power savings and a less-heavy headworn display are clear benefits, but the architecture presents many challenges. Having multiple, distributed sources of input or computational functions will require integrating, in real time, separate data streams into a cohesive model. In addition to the user's personal body-worn network, the merging and integration of computational functions could be performed on the edge or in the cloud, leveraging 5G in some cases.

This topic will include in its scope defining and testing different approaches to distributed sensors on the user's body and distributing processing capacity and assessing their impacts if any on device safety, weight, size, power consumption and cost, as well as calculating the utility/benefit ratio of different architectures.

","distributed computing architecture, body-worn mesh networks, body area network, sensor configuration, sensor control, head-mounted display device, wearables, cloud computing, sensor fusion, optimization, body area networks, off-display sensors, off-display processing, body sensor networks, personal area networks, mobile cloud computing, distributed computing, body area networks, wireless sensor networks, sensor fusion","Displays, Standards, Business, Technology","HMD manufacturers, AR display device designers, sensor developers, body area network manufacturers, OEM manufacturers, integrated solution and software developers","- Employees in AREA member companies frequently need simultaneous use of both their hands. Use of head-mounted displays represents a significant productivity improvement for those who need to use both hands and require contextually-positioned information to perform complex tasks.
- This research topic will contribute new knowledge aimed at addressing current limitations of head-mounted displays and will increase the quality of contextual data about the user and environment.
- The outcomes will reduce the barriers to AR display device integration with other devices and increase use of computational resources on and near the user.
- More flexible and distributed architectures are likely to reduce the HMD price and increase time between battery charges, and these benefits will increase adoption in the enterprise.","Studies of wearable sensors, low-latency body area network technologies, and sensor fusion processors and their synchronization will be necessary to examine all aspects of this research topic. A research platform composed of configurable head-mounted AR display components could be designed. Sensor data tracing systems may need to be tested or developed to provide a complete understanding of architectural choices.",Long,"This topic is at the intersection of multiple domains including but not limited to sensor configuration and control, sensor registrations, data filtering, sensor fusion, user context capture, and body area networks. The result could contribute to design of new HMD architectures, high-performance, and network-based resources and services (eg., 5G).","Studies of optical and IMU sensor fusion for AR HMDs date have been published as early as 2003. A https://www.researchgate.net/publication/281764749_An_Inertial_and_Optical_Sensor_Fusion_Approach_for_Six_Degree-of-Freedom_Pose_Estimation[recent publication on the topic] of 6DOF pose proves that the approach is very reliable.

The https://illixr.org/[ILLIXR Consortium] is developing a platform which, if extended to include body area networks, could be appropriate for experimentation with different architectures.","Peter Orban, Christine Perey",2021-08-31
3,Wearable vs Handheld vs Projection: Methods for Quantifying the Impact of AR Modality,"Tablets, mobile phones, and other handheld devices have been widely deployed in enterprise, including among frontline workers who use these devices to access contextually-relevant information while executing work procedures. Although hugely useful, their interaction paradigm forces workers to choose between carrying out the actual steps of a work procedure or interacting with the device. The choices the user makes can also present safety risks.

Commercially available wearable (head-mounted) displays enable frontline workers to consume context-relevant information while executing work procedures using both hands thereby – theoretically – speeding up work. The same could be true for projection-based AR approaches. And both approaches may decrease or completely mitigate safety risks innate to handheld devices. However, there is no independent assessment of the potential economic or safety benefits of the emerging, AR-enriched hands-free modalities.

This research topic focuses on the development of methodologies for performing objective, quantitative assessments of the impact of wearable and projection-based AR approaches compared to work procedures assisted by AR delivered using handheld devices. Measurement methods would be developed to ensure accuracy with a 95% confidence interval. The assessment methodology could include user acceptance of different modalities.

The research scope could be expanded to include performing comparative studies measuring the exact impact of wearable or projection AR modality vs. the handheld baseline across industries, use cases, and horizontal use case categories.

","efficiency, handheld, projection AR, wearable displays, head-mounted displays, usability, user perception, human factors, head worn displays, wearable computers,","Displays, Business","Operations leaders, financial management, OEM manufacturers, Independent Software Vendors,","- Wearable AR displays provide frontline workers in AREA member companies with information without requiring the user to hold a display in their hands or look away from their tasks while obtaining instructions.
- However, deploying display devices with entirely different form factors than those widely adopted, developing and deploying appropriate software, and integrating and training users on the new devices introduces time and expenses – particularly if handheld displays have been well-integrated in the current procedures.
- The AREA members need ways to measure and/or to calculate the investments and benefits of using different form factors in the workplace.","The research will contribute to development of tools to accurately, impartially measure the differences between handheld and wearable displays. The measurement methods will be used on groups of users sufficiently large in number and diverse in profile to allow projection across various attributes (e.g. time saved, quality improved, error eliminated, etc.). The research tools can include time-motion studies using standardized, public, well-documented processes typical of industry verticals, use cases, and horizontal use case categories.",Near,"This research can be combined with or extended to include different wearable form factors, including but not limited to monocular displays and binocular or holographic displays. The research scope may also be expanded to apply the same methods to study the return on investment of emerging use cases and AR in industries that have not been well documented.",The AREA RoI calculator is a starting point for quantifying the economic impacts of AR in repair and maintenance use cases. This research topic could contribute to the expansion of the AREA RoI calculator.,"Peter Orban, Christine Perey",2021-08-31
4,Impact of AR Delivery on People Living in Multidimensional Poverty,"The Multidimensional Poverty Index (MPI) ""measures the complexities of poor people's lives, individually and collectively, each year."" The measure was co-developed between the Oxford Poverty and Human Development Initiative at the University of Oxford and the Human Development Report Office of the United Nations Development Programme in 2010. It is a key measure for developing countries with regards to progress toward eliminating world poverty. Importantly, this specific measure accounts for many elements of non-monetary poverty to calculate an overall score, composed of three dimensions: health, education, and standard of living. According to the 2020 report ""Charting pathways out of multidimensional poverty: achieving the SDGs,"" ""this is a key moment to study how nonmonetary poverty goes down. It is 10 years before 2030, the due date of the Sustainable Development Goals (SDGs), whose first goal is to end poverty in all its forms everywhere. And it is a year when a pandemic and economic slowdown are pushing many more into poverty, while the spectre of racism still haunts, and environmental threats such as locusts surge.""

Because AR is a unique information delivery format that is highly conducive to providing increased accessibility to skill acquisition, learning, and even remote healthcare, and given the challenges that COVID has brought into the mix in 2020, UN nations will increasingly be looking for ways to sustain growth and minimize regression with regards to 2030 UN SDG targets. Because education accounts for 1/3 of the Multi-dimensional Poverty Index and this index is measured annually and can be applied flexibly to individuals, this is an ideal opportunity in time to investigate the impacts of AR with regards to reducing world poverty. There is likely to be substantial interest within local governments as well as amongst corporate entities supporting the UN 2030 SDGs.

This research topic focuses on measuring how access to AR systems for delivery of educational and healthcare programs over the course of a year impacts individual MPI. It will involve engagement with at-risk communities and require a combination of social and technological measurement tools.

","United Nations, Sustainable Development Goals (SDG), Multidimensional Poverty Index (MPI), poverty, policy, education, skill development, socio-economic effects, social aspects, social and economic effects, subjective testing, behavioral research","Business, End User and User Experience","Government officials and policymakers in World Bank Group and UN nations, social performance/impact executives in large, global organizations, particularly those with a large social license to operate - preference to industries in which corporations provide educational and healthcare services for many aspects of community life (e.g. metals and mining), education policy makers/professionals.","- Because AR is a unique delivery format that is highly conducive to providing increased accessibility to skill acquisition, learning, and even remote healthcare, and given the challenges that COVID has brought into the mix in 2020, UN nations will increasingly be looking to ways to sustain growth/minimize regression with regards to 2030 UN SDG targets.
- Because education accounts for 1/3 of the Multi-dimensional Poverty Index and this index is measured annually and can be applied flexibly to individuals, this is an ideal opportunity in time to investigate the impacts of AR with regards to reducing world poverty.
- There is likely to be substantial interest within local governments as well as amongst corporate entities supporting the UN 2030 Sustainable Development Goals.","The proposed research would need to decide upon a flexible scoring mechanism for individual MPI (see https://mppn.org/multidimensional-poverty/how-is-calculated/[multidimensional poverty calculation]).

The principal investigator would develop partnerships with a host corporation and community. Research would include calculation of pre-study MPIs and introduction of AR intervention via A/B trial scenarios, potentially with a few different levels of AR intervention. Then researchers would collect data about post-intervention behaviors and worker status.

Post-study MPIs could be calculated and recommendations developed for future implementation.
",Near,"This study could link closely with existing research programs associated with metals and mining, education, and policy, as well as potentially healthcare, depending upon the scope of the research project.","The Multidimensional Poverty Index (MPI) ""measures the complexities of poor people's lives, individually and collectively, each year."" The measure was co-developed between the Oxford Poverty and Human Development Initiative at the University of Oxford and the Human Development Report Office of the United Nations Development Programme in 2010. It is a key measure for developing countries with regards to progress toward eliminating world poverty. Importantly, this specific measure accounts for many elements of non-monetary poverty to calculate an overall score, comprised of three dimensions: health, education, and standard of living. According to the 2020 report ""Charting pathways out of multidimensional poverty: achieving the SDGs,"" ""this is a key moment to study how non-monetary poverty goes down. It is 10 years before 2030, the due date of the Sustainable Development Goals (SDGs), whose first goal is to end poverty in all its forms everywhere. And it is a year when a pandemic and economic slowdown are pushing many more into poverty, while the spectre of racism still haunts, and environmental threats such as locusts surge.""

References related to risk appetite matrices:
http://hdr.undp.org/sites/default/files/2020_mpi_report_en.pdf +
https://mppn.org/multidimensional-poverty/how-is-calculated/ +",Jennifer Rogers,2021-08-31
5,Passthrough vs. See-through: Impacts of Display Technology on Peripheral Vision,"Head-mounted AR displays (HMD) blend simulated reality with the real world while the user uses both hands. Some displays employ a ‘video passthrough' approach (e.g. Oculus Quest), where image processing and graphics rendering blend and display physical and generated reality in real time -- an approach that is used in all handheld AR display systems. Due to technology limitations, video passthrough wearable devices provide a field of view (FoV) between 90 and 120 degrees, thereby limiting the user's peripheral vision.

As peripheral vision is important for user safety, maintaining partial or full peripheral vision is required in many situations. Wearable AR display devices based on optical see-through technology have far lower impact a user's physical world FoV (i.e., they do not interfere with the user's peripheral vision), however, the FoV in which the user perceives digital assets varies.

This research topic focuses on determining the minimum FoV required for wearable video see-through AR display devices to meet workplace safety requirements. The result will provide HMD designers guidance with respect to the minimum FoV (possibly foveated) that must be supported in video see-through in order to provide user experience comparable to the best-in-class optical see-through AR displays.

","video see-through, video passthrough, field of view, waveguide, birdbath, off-axis, light field, foveated rendering, human eye resolution, head-up displays, three-dimensional displays, micro displays, computer displays, liquid crystal displays, display devices, led displays, screens (display), color displays","Displays, Technology, End User and User Experience","Operations leaders, HMD designers, Safety & IT managers, OEM manufacturers, ISVs","- Most of the leading AR display component and system manufacturers are AREA members.
- Video passthrough displays using existing technologies for graphics overlay on video are less expensive to develop than optical see-through displays.
- AREA members would benefit from having objectively defined measures of the impact of head-worn video see-through displays on the user's peripheral vision.","Studies of human peripheral vision requirements and sensitivities to FoV constraints will need to be performed in highly controlled research conditions. A research platform composed of configurable head-mounted AR display components could be designed. The video passthrough experiences designed for the study will need to have the same level of latency as an optical see-through display and their weight and other ergonomic factors would need to be identical in order to study only the impact of the technology on user's vision. Eye-tracking data could be used to measure the user's gaze and extensive user interviews or other measurement systems would be needed to capture the impacts of the options on eye fatigue, cognition, and task performance.",Near,This research can be combined with or extended to include different wearable form factors including but not limited to monocular displays and binocular or holographic displays. The research scope may also be expanded to apply the same methods to study user safety and comfort. It is also highly valuable to explore how the video and optical see-through displays differ in producing highly registered AR experiences and permitting other optical features.,"Although quite dated by today's stamdards, one of the https://www.researchgate.net/profile/Jannick-Rolland/publication/220089776_Optical_Versus_Video_See-Through_Head-Mounted_Displays_in_Medical_Visualization/links/0fcfd50f59745391b5000000/Optical-Versus-Video-See-Through-Head-Mounted-Displays-in-Medical-Visualization.pdf[first studies focusing on this topic] was performed by Dr. Jannick Rolland and Dr. Henry Fuchs to examine the pros and cons of these two display options in a surgical use case. The study was published in the journal ""Presence"" in 2000.

The topic of mitigating parallax-related registration errors is a highly active field of study, as demonstrated by
https://www.frontiersin.org/articles/10.3389/frobt.2020.572001/full[this article published in December 2020] in the Frontiers in Robotics and AI journal.","Peter Orban, Christine Perey",2021-08-31
6,New Power Sources for Wearable AR Displays,"As the complexity and computational requirements of world capture, world analysis, scene management, rendering, and human interactions with AR experiences increase, a delicate balance must be struck so as to ensure that the useful life of a device between recharges is not too low. Power management may be addressed through a combination of different approaches, including increase in use of low power DSPs, off-loading some computational tasks to the edge of the network (off-device services), and increasing power storage capacity. There is another potentially powerful resource to address the duration of wearable AR display usage. This topic focuses on the research and development of novel methods to capture power from the user or the environment that could be transferred to the power storage system.

Specifically, the proposed topic will research, build, and test implementations of new methods of energy harvesting from sources that have not been used in prior wearable AR display systems. There will need to be studies of human movement (steps, arms, hands), solar sources for users that are outdoors, and chemical reactions that release energy. This topic will span a wide range of technologies, including analysis of the power requirements of each individual AR display component.

","power use, power consumption, power production, AR device energy sources, energy capture, energy production, AR device energy transfer, energy consumption, energy management, electromechanical, solar energy, friction, power storage for AR displays, human factors, weight, usability, portability, computational efficiency, low power electronics, electric batteries, power consumption, power conversion, power aware computing","Displays, Technology","All users of wearable AR display devices and those who manage their use in the workplace will benefit from longer duration between recharges. Introducing or integrating novel power production, transfer, and storage technologies will have impacts on display costs, which could affect the number of devices purchased.","- Most of the leading AR display component and system manufacturers are AREA members.
- Use of wearable AR displays in AREA member settings is limited by many factors, one of which is the size and weight of the display needed in order to store sufficient energy to power the computational processing requirements of AR experiences.
- The issues of power storage to deliver energy for a full work shift can be addressed through reducing local (on-device) processing and power requirements, and increasing storage capacity.
- Having continuously generated power from a source such as the movements or environment of the user is an approach that has not received extensive study but could introduce an attractive alternative to removing a device from use for charging.","The research will be leveraging developments in physics, chemistry, and other sciences pertaining to energy production and combining those with deeper studies of wearable AR display device power use. In addition to theoretical calculations, there will need to be prototypes developed and tested to measure the efficacy and efficiencies of power capture, storage, and use with AR displays. Finally, the introduction of new energy production, transfer, and storage methods or systems will need to be carefully studied for their safety in the workplace.",Long,"This research topic could be studied in different environmental conditions, such as indoors, outdoors, and in different temperatures. In addition, there will need to be studies of different use cases in which some users are actively moving throughout a work shift. The results of this research would also be very valuable for non-enterprise users and display devices.","This field of research is in its infancy, but there are some promising developments such as the electrochemically driven mechanical device developed at MIT and https://www.nature.com/articles/ncomms10146[revealed in 2016 in Nature].

The following articles, published in 2019 describe https://techxplore.com/news/2019-11-harvesting-energy-human-body.html[energy harvesting based on human body movement]; similar studies have been https://www.sciencedaily.com/releases/2019/07/190717122600.htm[reported here.]

This study of https://res.mdpi.com/d_attachment/energies/energies-13-03871/article_deploy/energies-13-03871-v2.pdf[measurement of the power produced] was published in 2020.",Christine Perey,2021-08-31
7,Low Power Digital Signal Processors for Use in AR Display Devices,"While the data about the user's context is captured, fused, and filtered in one digital signal processor (DSP), vision processing units (VPUs) are analyzing individual and fused data signals to detect key features (e.g., objects) of the real world. Audio processing also requires computing resources. At the precise moment when AR experiences are delivered to users, power is needed for the rendering computations. This power usage must not compete with the power necessary for the optics, auditory, or other real time processes to produce digital assets visible to the user.

DSPs are common components of AR Systems-on-Chips (SoCs) in displays. The DSPs accelerate the classes of computational tasks required for optimal performance of AR systems. They can be configured and optimized to specific parameters, matching the sensors that capture the real world tasks that they perform and even the use case or user's requirements.

To reduce total display power usage and increase the time between charges, fundamental research needs to advance the state of the art in design and production of low-power DSPs dedicated to every computationally intensive component of enterprise AR displays and delivery systems.

This research needs to be performed without interference with existing patents and be published and available to component manufacturers and AR display manufacturers without license or fees in order to accelerate the development of new DSPs and to reduce the cost of high-performance enterprise AR display devices and other mobile hardware.

","Low power, power use, power consumption, digital signal processing, DSP, VPU, SoC, AR display hardware, digital signal processing, low power electronics, heads-up displays, power consumption","Displays, Technology","AR display designers, AR display manufacturers, original equipment manufacturers (OEM) of semiconductors for AR displays, AR systems integrators","- Most of the leading AR display component and system manufacturers are AREA members. While their research in this topic has certainly led to substantial improvements in performance, there has been a lack of peer-reviewed literature published on the topic.
- There must be greater research investment and publication of results focused on the challenges of power consumption and computational complexity in order to create new business opportunities that can benefit all AR display manufacturers.
- AREA customer segment members will also benefit from lower cost, less power-intensive systems and integrated AR display devices as a result of advancements in this field.","Semiconductor and DSP designers can collaborate with other AR ecosystem segments to increase their understanding of the diversity of real world requirements. Using machine learning and artificial intelligence, designers will optimize new DSP architectures for AR-specific functions.",Long,This research can be combined with fresh research approaches to create new power capture and power storage technologies for use in AR display designs.,"A 2018 https://www.qualcomm.com/media/documents/files/the-mobile-future-of-augmented-reality.pdf[Qualcomm Technologies presentation] describes important computing tasks and functions of signal processors in advanced AR display devices.

This is a https://community.arm.com/innovation/b/blog/posts/maximizing-the-system-efficiency-of-augmented-reality-devices[blog post] published June 2020 on the ARM community web site about this research topic.",Christine Perey,2021-08-31
8,AR Visualization of Body Sensors for Worker Biofeedback,"During the performance of tasks or fulfilment of roles, an employee may be unaware of changes in their involuntary bodily functions such as blood pressure and heart rate. When aware of any unusual metrics, the user can choose or be prompted to take appropriate actions. Visual and/or auditory information captured in real time by body-worn sensors (e.g., watches) could capture posture, head flexion and extension, whether the arms are above the shoulders, and possibly even squatting. The system could provide feedback on static posture duration and/or frequency and suggest postural changes or breaks based on criteria that increase the risk of muscular skeletal disorders.

The sensor data can be provided to the AR display through a body-area network. This topic focuses on the low-latency transmission and processing of observations from body-worn sensors to the user's AR display and the presentation of data and recommendations in a compact and actionable manner. The system design research should explore both automated modes (which are triggered upon the user's functions reaching a threshold) as well as manually controlled modes (e.g., enabled by a user seeking to obtain vital statistics). There must also be research to ensure that any AR visualization system is secure and upholds all relevant user data privacy protection policies.

","Biometrics, body sensors, blood pressure, heart rate, body temperature, body-area network, biofeedback, user data privacy protection, visualisation, alerts, biofeedback, biometrics, body area network","End User and User Experience, Technology","Companies monitor and manage workplaces for their suitability to employees. This research will be valuable to all workplace health and safety professionals, wellness specialists, human resources managers, user data privacy policy analysts, employees, and managers.","- Employees of AREA members may work in conditions that are highly stressful and/or require postures that introduce risk of injuries. Others must concentrate while working in environmental conditions that are known or anticipated to produce risks to employee well-being (e.g., around vibrations or loud machines). Body-worn sensors can detect abnormal behaviors in the workers' involuntary bodily functions, postures, and use of body parts.
- The implementation of body-worn sensors could be controversial if their ability to protect user data privacy is not clearly demonstrated.
- By using a body-area network and connecting it with their AR display, an employee will be able to see any anomalies in their real time and historical biometrics without distracting them from their task or releasing their personal data.
- With biometric information in their field of view, the AREA employee can modify their behaviors (e.g., reduce stress, change posture, or make other adjustments to manage their body's response to conditions in their workplace).","Research on this topic includes testing and studying the features of body-worn biometric devices in professional settings. It will be necessary to design and build a body-area network supporting existing standards in order to interface with radios and technologies on AR display devices. The research will also require designing and studying the usability, efficacy, and performance of AR-enriched user interfaces for providing a user with only pertinent biometric data via an AR display.",Medium,"This research topic can be combined with other topics pertaining to automated alerting of users to risk conditions using the AR display. It can also extend research on biometrics, biofeedback, and behavior modification therapies.","A peer-reviewed study of a biofeedback system combined with a VR display for managing emotional states was https://dl.acm.org/doi/abs/10.1145/3089269.3089273[published in SIGGRAPH '17 proceedings]. As documented in this https://res.mdpi.com/d_attachment/applsci/applsci-09-03248/article_deploy/applsci-09-03248.pdf[2019 review of the state of the art of body-area network usage in healthcare], the technology is maturing. Combining body-area networks and AR in professional domains is an unexplored field that has high potential for impact.

Similarly, biometrics and the use of biofeedback in the workplace are very large and active fields of research. However, to date, their intersection with Augmented Reality has not been documented in the peer-reviewed literature.",Christine Perey,2021-08-31
9,Development of Heuristics to Assess Enterprise AR Experience Design and Usability,"Usability heuristics are lists of design guidelines that developers and practitioners can use to evaluate the usability of applications in the design and development process. A heuristic evaluation is an activity conducted by a usability expert that involves a checklist of best practices. Applications are judged on their adherence to the checklist items, and the results are used to refine the application design so that it better meets the end user's needs.

While there are several general usability heuristics available for software interfaces (e.g., Nielsen’s 10 Usability Heuristics for User Interface Design, Schneiderman’s Eight Golden Rules of Interface Design), there have been no heuristic checklists developed specifically to assess AR experiences for the workplace. Using a heuristic checklist targeted to enterprise AR reveals aspects beyond the general best practices that are unique to AR environments. This includes characteristics such as safety, comfort, user interaction methods, hardware setup and capabilities, and privacy.

This research topic involves the development of a new heuristic checklist for enterprise AR experience developers and practitioners to use to evaluate the usability of AR experiences and accompanying hardware.

","usability, user experience, heuristics, best practices, product design, software design, user centered design, design, hci design and evaluation methods","End User and User Experience, Industries, Technology","Developers, users, operators, users of AR applications","- This topic is of interest to AREA members because it helps to define best practices for AR application design.
- The outcomes of this effort will allow providers of enterprise platforms to more quickly and reliably assess usability and UX, which in turn will facilitate informed iterative design/development, resulting in more satisfying, efficient, and effective solutions.
- It is important to note that this checklist will complement user testing – it is not a replacement by any means.","Quiñones, Rusu, & Rusu (2018) outline a formal methodology for developing usability/user experience heuristics. The method has been applied in a number of domains outside of enterprise AR and validated by experts. This method involves a systematic literature review, examination of the experimental literature, detailed analyses of the characteristics heuristics should have in the domain, and three levels of validation.",Medium,This topic is academic in nature though the resulting heuristic checklist should be validated with many AREA stakeholders in a variety of domains and industries to ensure robustness and generalized usefuless among the wide range of AR applications used in enterprise settings.,"Details on how to develop a new set of heuristics for a domain are discussed in work by Quiñones, Rusu, & Rusu (2018) https://www.sciencedirect.com/science/article/pii/S0920548917303860?casa_token=9AqOOBdQFFQAAAAA:cIiacrm7bZ0rsL2UtTdLgQqgF1FnA6KZLknce5cphvYbiPh2fSZeNGoDXldyDpbspVWWD_4HnA/[in this article].",ERAU Team,2021-08-31
10,Impact of Spatial Vision on Visual Encoding and Memory Anchoring,"Some complex instructions and illustrations used in training or on the job require greater time and cognitive load for workers to understand, retain, and use when displayed in planar mode (2D). Three-dimensional representations and spatial vision enabled by stereoscopy has been shown to increase comprehension of spatially relevant concepts and increases their encoding and retention in memory. Although technology today enables spatial vision, frequently it requires some level of compromise around performance, wearability, or resource requirements.

This research topic focuses on measuring the impact of binocular (vs monocular) vision on short- and long-term memory encoding (i.e., the process of changing sensory inputs into forms that are stored in the brain and anchored in such a way that enables effective retrieval).

","spatial vision, spatial memory, visual encoding, memory anchoring, spatial frequency, receptive Field, modulation transfer function, high spatial frequency, threshold contrast, spatial strategies, spatial orientation, object location, stereo image processing, image coding","Displays, Technology, End User and User Experience","user experience designers, AR experience developers, human resources professionals, AR display designers, AR display manufacturers, researchers studying cognition and performance of users in the workplace","- All AREA members seek to reduce cognitive load and increase performance and memory encoding of workers during the performance of complex tasks.
- To date, the role of stereoscopic vision in AR experiences in spatial understanding and memory has not been studied. When these are better understood and the impacts are quantified, designers of experiences and interfaces will be able to accelerate memory anchoring and spatial awareness.
- Determining the specific contributions of AR to human memory and cognitive functions will contribute to calculating return on investment on AR in enterprise, justifying investments and removing enterprise AR adoption barriers.","The research topic would need experts to develop and use a combination of existing neuro-analytical tools (tools that measure neurological brain activity) and biometric tools that infer neurological responses by proxy. The former includes EEG, fMRI (functional MRI), fNIRS (functional near-infared spectroscopy) and steady state topography (SST), all of which directly measure brain activity related to specific brain functions. For instance, SST measures the speed of electrical activity on the surface of the brain, linking changes in certain areas to specific metrics like engagement and memory encoding. The latter includes eye tracking, facial coding, and biometric data like heart rate monitoring. This research will analyze data for broader interpretation, offering insights into the use and impacts of 3D spatial viewing with AR, compared to measurements made by technology like SST and fMRI.",Near,This research topic can be integrated with fundamental research on brain function. It could also be combined with studies of specific use cases in which the system recalls the users' spatial vision strategies and enhances those selectively. User experience design would also benefit from studies of this and related neuro-analytical tools and topics.,"There has been research published on the topics of https://www.sciencedirect.com/topics/neuroscience/spatial-vision[spatial vision] and more specifically on AR and https://www.frontiersin.org/articles/10.3389/fnhum.2019.00113/full[memory encoding].

https://www.frontiersin.org/articles/10.3389/fnhum.2019.00113/full[This 2019 article published in Frontiers in Human Neuroscience] reports on research conducted using AR to assess the impact of gender on spatial vision and anxiety.","Peter Orban, Christine Perey",2021-08-31
11,Text Input with AR Head Mounted Displays,"Most AR experiences developed for mixed-reality head-mounted displays require some level of user interaction, such as text input, gestures, or voice input. While voice is the quickest method for a user to control and interact with digital assets, it is prone to error thanks to varying speaking styles, accents, and emotions. It is also not well suited to noisy industrial environments. Text input is typically conducted through hand or finger gestures or a handheld clicker with a virtual QWERTY keyboard. Research examining user performance reveals that both methods are cumbersome, with an average of 5-6 WPM. (For comparison, typical typing speeds on mobile devices range from 30 to 50 WPM.) This performance level is unacceptable for continued and effective use in the workplace. In addition, users may feel fatigued after holding their arm in compromising positions for extended periods of time.

User acceptance and satisfaction is critical and a common struggle among developers of alternate keyboard design, even outside of the HMD/AR domain. The QWERTY keyboard, for example, has been shown to result in slower performance than alternative designs, but the general public is unwilling to relearn a new method.

This research topic involves the study of alternate methods of text input to develop methods with higher performance and user satisfaction. The approaches to be studied include the design of a virtual keyboard and advancing the algorithms behind the keyboard predictive text functionality and user interaction (i.e., tap gesturing vs trace, eye gaze input).

","text entry, text editing, virtual keyboard, trace input, user experience, sensory perception, text analysis, gesture recognition, keyboards, speech-based user interfaces","End User and User Experience, Displays, Technology","Developers, operators of machinery, all users of AR experiences requiring user input of text, performance and quality control managers","- Almost all AR experiences used with wearable displays require some level of user input of alphanumeric information. - - Improving input methods to increase the speed and quality of input so that it is easy to use, efficient, and not prone to error will provide for better user experiences and more widespread AR acceptance.","Researchers interested in this topic may examine the efficacy of the virtual keyboard design itself, the method of user interaction (speech, gesture type), or the predictive text algorithms used. A combination of objective measures (e.g., time (WPM), error rates) as well as subjective measures (e.g., user satisfaction, acceptance, preference among methods, likelihood to use) should be examined.",Medium,This topic examines the overall issue of text input using AR experiences and interfaces with a wearable AR display device. It is expected that researchers will examine one of the aforementioned methodologies and not all in a single study. The research is best done in controlled environments to determine optimal performance before generalizing to applied settings. Time and motion studies could be employed for performance assessment/metrics. Interviews and surveys are needed to explore user acceptance of different text input options.,User performance and subjective data of text input using a HoloLens device can be seen in https://journals.sagepub.com/doi/pdf/10.1177/1071181319631279/[this article].,ERAU Team,2021-08-31
12,Facilitated User Interactions for Selecting and Manipulating 3D Models in AR,"Computer-generated models and models derived from scans of objects are increasingly part of product designs and testing activities. They are also valuable in diagnostics, and guiding assembly, repair and maintenance procedures. Today, many AR experiences use only 2D targets and display 2D line drawings, text, and images. However, in the future 3D models will increasingly be used for object recognition, tracking, and registration of experiences. Models will also be displayed over real-world objects for instructions or ""hanging"" in space when two or more collaborators need to examine the same object. Users will need to manipulate and interact with the models.

Unfortunately, the tools (e.g., pointing devices) and conventions (e.g., gestures and voice commands) for the selection and manipulation of 3D models in AR are unfamiliar and challenging for users. Most models lack clearly labelled anchors, handles, and other indicators that would reduce the barriers to user interactions. When there are multiple models in a scene, users may be unable to select one for closer examination. Users must learn advanced techniques and concentrate to perform simple manipulations such as open, close, and hide, not to mention advanced manipulations such as rotate, scale (enlarge and shrink), attach, move to back, move forward and other actions that may increase the value of a model in AR experiences.

This research topic focuses on the design, development, and evaluation of computer-human interactions and computer graphic techniques to improve the ease-of-use of 3D models in AR experiences. When research results are published in peer-reviewed journals, there will be greater diversity in solutions and more innovation based on a deeper understanding of the options and trade-offs involved.

","3D models, selection, manipulation, anchors, labels, handles, rotation, scale, attach, human computer interaction, computer human interaction, computer graphics, computer human interaction, computer graphics","Technology, End User and User Experience","This research is relevant to designers and managers of enterprise 3D assets, 3D asset platform publishers, AR experience developers, AR program managers, and AR authoring platform publishers.","- AR experience developers and employees in AREA customer segment companies will have many use cases involving the selection and manipulation of 3D models. However, the acceptance and value of 3D models will be low until there are improvements in how models are prepared, presented and manipulated during AR experiences.
- The proposed research topic will benefit AREA members by increasing 3D model usability, lowering cognitive load, and increasing the impact of 3D models in the workplace.","The research will build and publish a set of 3D models that objectively represent what would be used in workplace settings where AR is used. The models will be designed with features such as anchors and handles. Studies will compare approaches developed in commercial software for 2D screens with those proposed in AR and VR game engines and experience authoring platforms. In laboratory settings, users will be given tasks to perform with 3D models while using different models of wearable AR displays. In addition to time-motion studies and ergonomics, user testing will measure strain and cognitive effort when performing tasks that require model selection and manipulation.",Near,"This research topic could be combined with studies of 3D capture, computer graphics, and 3D model registration and annotation. Research pertaining to AR user interfaces and interaction could also be extended to include 3D model selection and manipulation. The study of hand tracking would contribute to exploring use of gestures for simple and advanced model usage.","Microsoft has published several papers and best practices on this for HoloLens, hand tracking, and gestures, but these are exclusively implemented in one platform and there has not been extensive comparison using quantitative methods. This topic was proposed for consideration in 7th AREA research project topic call and received high member interest and support.",Christine Perey,2021-08-31
13,What Factors Influence Perceptions of Presence?,"Presence is a term used to describe the ""feeling of being there"" in a virtual environment. It can be cognitive, in that the user's mind is engaged in the virtual content, or it can be perceptual, in that the user's sensory systems perceive the virtual environment to be ""real."" In Augmented Reality (AR), this is represented by a seamless integration between the physical and virtual worlds.

A question that arises in this area of research is what factors of the virtual environment influence the perceptions of presence? Is there a minimum amount of virtual information needed in an AR environment? Does the level of fidelity of the virtual elements influence the reported experience of presence? For example, will an application that uses realistic 3D models result in higher levels of presence than lower fidelity (i.e., cartoon) 3D models?

In VR worlds, the user is immersed into a completely virtual world, so presence is likely to be experienced if the application is successfully implemented. In AR environments, users are exposed to virtual elements in addition to their physical surroundings. If a user has to switch their attention between the two worlds to complete a task, the result can be disruptive and/or fatiguing due to the lack of presence. If the user can complete the task as if the virtual elements are part of the physical world, the result is a seamless, productive experience that includes presence. It also is possible that lower fidelity serves as a distraction to the user, which may result in breaks in immersion and a reminder of the artifical nature of the virtual world. This could, in turn, impact their sense of presence.

A practical example of this issue is with the use of avatars in collaborative environments. How is presence affected by the appearance and customization of the avatars? If a user pays attention to a particular feature or abnormality due to low fidelity rendering, it may impact their ability to perform the task at hand. Another example may be dynamic elements in the virtual world, such as a bouncing ball or a spinning tire. How distinguishable, in appearance and in behavior, the object is from its physical counterpart may influence the level of reported presence.

The main research question in this area is ""How much virtual information of what fidelity is necessary in an AR environment to produce a sense of presence?"" This question is of interest at both ends of the quantity spectrum -- how much is enough, and how much is too much? Too little and the user will not experience presence; too much and the user may become so immersed in the virtual elements that awareness of the physical world may be compromised.

This research topic involves the examination of AR environments with differing amounts of virtual elements at different levels of fidelity and the measurement of presence among users.

","presence, immersion, awareness, realism, cognitive tunneling, mental workload, seamless experience, high fidelity, low fidelity, realism, avatars, object interaction, display technology, presence, interactive computer graphics, user experience, cognitive systems, sensory perception, avatars, computer graphics, color computer graphics, holographic displays, animation, image quality","End User and User Experience, Industries, Technology","Developers, users, operators, users of collaborative virtual environments

# Position on X and Y axes (1-5)","- AREA members will benefit from having new ways to define effective AR application environments from the end user perspective.
- Deeper understanding of presence and when immersion is broken will reduce how frequently an operator must shift their attention, which may cause cognitive tunneling associated with decreased awareness of critical elements in either environment, higher perceptions of mental workload, safety issues, and decreased productivity.
- Understanding the level of fidelity necessary to achieve optimal presence will help AR developers know the appropriate effort and resources to invest in specific use cases.
- The research will also assess if and how impact of fidelity may also be task dependent. For simple assembly tasks, for example, the level of fidelity may matter less than for collaboration tasks where several avatars work together to solve a problem.","Presence tends to be a self-reported measure assessed by means of a questionnaire. Physiological measures also may be explored to correlate with reported presence, engagement, and satisfaction. These measures could be systematically compared across environments of varying complexity in terms of number of virtual stimuli for a variety of tasks.",Medium,This topic is related to other proposed AREA Research Agenda topics on display technology and user perceptions and satisfaction.,An interesting article related to the amount of physical space in which AR application is used can be found https://ieeexplore.ieee.org/document/8943577/[here].,ERAU Team,2021-08-31
14,Impact of Individual Differences and AR Display Comfort on User Acceptance,"Head-mounted AR display devices are getting lighter and more comfortable. However, users may still perceive the weight on their necks and find the devices cumbersome to don and doff, as well as finding them hot after extended periods of use. Head sizes, head shapes, visual acuity, inter-pupillary distance, and the use of corrective lenses or safety glasses/safety helmets all affect users' comfort and ease of use. While advances in the technology that accommodate wider ranges of users are rapidly being deployed, industry adoption can be hampered by poor user acceptance due to general discomfort.

This research topic examines impacts of individual differences on user satisfaction and acceptance of a variety of HMD devices in the workplace.

","comfort, eye strain, fatigue, simulation sickness, heat tolerance, headgear weight tolerance, subjective testing, behavioral research, thermal comfort, environmental factors, comfort","End User and User Experience, Industries, Technology","Developers, users, operators, users of AR head mounted displays (HMDs)","- User acceptance of new form factors in display technologies is critical to AR adoption. Since comfort is known to impact user acceptance of AR in the workplace, all obstacles need to be identified and accommodations made for individual preferences and features.
- Understanding individual differences also contributes to the understanding of OEM and designers about which differences remain to be addressed by the various HMD technologies.","Comfort can be measured both objectively and subjectively. Objective measures include pupil diameter to assess workload or cognitive effort, EEG, and GSR. Subjective measures include Likert scales querying perceived comfort, exertion (i.e., Borg Scale or Perceived Exertion), assessments of HMD weight, thermal comfort, acceptable length of use, and general acceptance.",Medium,This topic is potentially related to another proposed AREA Research Agenda topic on Users and User Experience [Einput-textinput] in that comfort is a key component to user acceptance of various text input methods. The topics could be combined with other AR End User and User Experience topics to develop a full research program.,An interesting article regarding the design decisions of the HoloLens 1 to accommodate individual differences https://sid.onlinelibrary.wiley.com/doi/pdf/10.1002/sdtp.11586?casa_token=i1x9dRJa2tAAAAAA%3AmnQU3ckNbdunIDNe4G8uxoLfe87YwzEpS7Ti1G0N9L76PgNLHarmCNusU9C9U9ucswKxB3wtRUFUdyM/[can be found here].,ERAU Team,2021-08-31
15,Visualization of Targets Invisible Due to Atmospheric Conditions,"When conditions prevent mechanical or visual scanning of environments and providing of situational awareness using vision-based technologies, there need to be alternatives. The goal of this research is to provide users (decision makers such as pilots, drivers of cars or vehicles, operators of equipment at night or in blizzard conditions) an accurate visualization of the real-time conditions of a moving machine (e.g., automobile, aircraft, tank, truck) when the surrounding atmosphere is entirely or nearly opaque or the light conditions are not favorable for use of vision-based sensors.

Although identified/scored as an aviation-industry specific topic, the scope of this topic is very broad and results could be applied in many industries (e.g., automotive). The topic spans everything from the use of non-visual sensors (e.g., sonar) for depth to the development of new computer-human interfaces for 3D data visualization.

","situational awareness, night vision, non-visual scanning in real time, aviation and aerospace, military, reconnaissance, occlusion, depth of field, automotive, sensor fusion, data layers, ToF (Time of Flight) sensors, computer vision, autonomous vehicles, user experience, night vision, aircraft navigation, avionics, aircraft displays, air navigation, aircraft detection, automotive, user experience","Industries, Displays, Technology","AR experience developers, operators and owners/users of commercial, private or military aircraft","- Almost all existing AR products for outdoor situational awareness rely on RGB or RGBD cameras for real-time environment acquisition, yet the visualization of obstacles or other salient features of the physical world in atmospheric conditions unsuitable to vision-based sensors cannot serve as the basis for decision making for users.
- AREA members with use cases in industries that could use AR in environments with low visibility are not currently able to reliably deploy the technology.","Acquisition and/or development of lightweight and power-efficient infrared sensors that are effective as alternatives to cameras and existing vision-based environmental capture. Testing and development of 3D interaction modes when user's natural vision is impaired. This research topic could explore IR sensors (which measure differences in temperature, also known as ""thermal imaging""), as well as new alternatives.",Medium,"This topic of research overlaps with the topic of using AR to visualize any stationary or moving object in low-visibility conditions. The outcomes of this research could also be applied in non-industrial use cases (e.g., skiing or other sports in low visibility-conditions). The same research topic could be combined with study of user interfaces and interaction paradigms for the visually impaired community.",The use of night vision technologies is widespread in the military/defense industry. There have also been studies of the use of AR for https://sciencebusiness.net/network-news/air-traffic-control-improved-augmented-reality[air traffic control].,Christine Perey,2021-08-31
16,Visualization of Temperature Sensor Data in AR for Emergency Response,"The use of thermal imaging data from handheld devices for identification of bodies in smoke-filled spaces has been in use to save lives for decades. This topic is not intended to study that use case. Several companies have successfully integrated the thermal imaging sensors into commercial PPE (""smart helmets"") worn by emergency responders.

This research topic will instead focus on advancing the state of the art of thermal vision. There could be extension of the types and size of thermal imaging technology suitable for including in AR-assisted emergency responses equipment. Currently, thermal imaging produces data in only 2D. Research into visualizing the heat source in 3D will be beneficial. In addition, the research should explore different methods for users to interact with the data displayed on their helmets, new and novel methods of distinguishing between heat-emitting sources detected using thermal imaging and combining the information about a building's floor plan with the thermal imaging to trace safe routes to use when reaching targets under time constraints.

","thermal imaging, 3D data visualization, smart helmets, Personal Protective Equipment, fire fighting, route tracing, 3D data interaction, public safety, ","Industries, Displays, Technology","While the emergency responder and military use cases are the clear beneficiaries of this research topic, there are also applications in automotive, such as displaying to a driver moving or stationary wildlife along a road side or forklift drivers ""seeing"" the thermal image of pedestrians in a warehouse or in a manufacturing environment. Additional imaging could prevent hazardous interactions. Similarly, when mounted in field equipment, the AR display can alert a driver to the presence of people or animals in the path of the equipment. When the technology is miniaturized and highly reliable, it may be used in enterprise AR use cases including but not limited to medical industry or animal husbandry for diagnostics and therapeutics. If the cost and size of the technologies is sufficiently low, the feature could be used for non-industrial applications, such as in games or education.","- When AR displays with thermal imaging are widely available for enterprise users, AREA members in government, automotive, aviation, medical, agriculture, and other industries will find it valuable to have more use cases for their AR investments.
- Adding new and diverse sources of live data to an AR display can increase cost and power use, but also introduce new use cases for AREA members.","The study of thermal imaging and design of new sensors for heat mapping will involve expertise in physics and engineering. Adapting new sensors to fit the AR display form factors for prototyping and user testing will require skills in electromechanical domains, semiconductors, and industrial design. In addition to research about thermal sensors, there will need to be research on user interaction with 3D thermal images.",Medium,"This topic can be combined with studies of other sensors that permit users to visualize through water, atmospheric conditions, and physical obstructions (e.g., walls). The study of sensor integration could also be extended to span visualization of a user's vitals (heart beat, blood pressure, etc.) and 3D interactions.","This topic was the focus of work by students at EPFL (Switzerland) in 2015. The students working on this project https://actu.epfl.ch/news/augmented-reality-for-firefighters/[developed a thermal imaging smart visor] in 2016.

There was also a http://fayez.me/papers/ICIP-2018-Paper.pdf[peer-reviewed journal paper] published by one of the EPFL faculty working on the above project in 2018.

In 2019, Darix, the start-up that was created out of the EPFL research, https://actu.epfl.ch/news/ic-spinoff-darix-acquired-by-bullard/[was acquired by Bullard].

Longan Vision, another company in this field, has been https://spectrum.ieee.org/the-institute/ieee-member-news/startups-thermal-imaging-and-ar-system-for-firefighters-joins-the-covid19-fight[adapting their system for Covid].",Christine Perey,2021-08-31
17,AR for Crop Preservation in Food-Insecure Countries,"Food and nutrition security remains a huge challenge across the globe, particularly as the frequency of extreme climate events increases. The Integrated Food Security Phase Classification (IPC) indicates the level of hunger/starvation present in a particular country or region due to insufficient crop supply. The Food Security and Sustainable Agriculture (FSSA) ""resilience-building thematic mechanism aims to ensure the complementarity of instruments for high-impact aid. It had an indicative budget of €525 million over the 2014-2020 period."" Additionally, ""sustainable food security"" remains a priority for the world economy, with the EU Project Horizon 2020 work programme identifying the following immediate needs for further research and innovation:
- Identification of tools and methods, mainly at the farm level for soil remediation and balanced fertilizers application;  +
- Identification of agricultural system approach that can enhance quality of soils for food production; +
- To raise public awareness about soil as a crucial global resource; +
- Enhance EU-China long-term cooperation in land use optimization for global food and environmental security.

This research topic focuses on how AR can be used to permit farmers to investigate their crops, while layering additional information such as water saturation metrics from IoT data, as well as even potentially an AI component that could categorize types of erosion and/or plant disease and provide real-time feedback with regards to required human intervention. The use of AR in agriculture could be adopted or subsidized by fertilizer corporations, water providers, and other members of an agriculture ecosystem. When those in the field use AR, providers of products and services would be able to connect from a distance and provide real-time advice for farmers and other end-clients.

This study would aim to specifically measure the impact of data-informed AR on crop preservation, particularly in food-insecure countries.

","United Nations, Sustainable Development Goals, sustainability, policy, education, skill development, socio-economic effects, artificial intelligence, IoT, crop preservation, farming, agriculture, water preservation, social aspects, social and economic effects","Business, End User and User Experience, Industries","Government officials and policymakers in World Bank Group and UN nations, social performance and impact executives in large, global organizations, particularly those with a large social license to operate, sustainability/innovation groups in large corporations, executives and sales teams in agriculture","- AR can provide a vital channel with which to establish a vibrant food production ecosystem positioned to support and connect farmers across the world.
- Large impact can be made by utilizing existing soil/plant photography databases and AI-driven, AR-facilitated guidance, as well as incorporation of IoT data pertaining to water availability, as many food-insecure nations experience hardship associated with frequent drought.
- AR is a unique delivery format that is highly conducive to providing increased accessibility for remote, rural farmers and lowers traditional barriers associated with varying literacy levels, etc.,
- Introduction of AR opens up a myriad of possibilities with regards to establishing and expanding markets.
- There is likely to be substantial interest within local governments as well as amongst corporate entities supporting the UN 2030 Sustainable Development Goals. There is also great potential for interest amongst providers within the broader agriculture value chain.","The proposed research would need to enroll and engage rural farmers in food-insecure areas, preferably those in which agriculture is practiced in remote or at-risk locations (e.g. retired mine site, etc.). The research would also need to develop or expand and leverage databases of photos for local plant and soil conditions.

Rural farmers would need to be onboarded into technology pilots, and potential ecosystem partners (e.g. water providers, fertilizer providers, etc.) would need to be identified. The principal investigator would develop partnerships with a host corporation and community. Research would include IoT data pre- and post- introduction of AR intervention via A/B trial scenarios, potentially with a few different levels of AR intervention. Then researchers would collect data about post-intervention behaviors and crop status.

Post-study outcomes could be analyzed and recommendations developed for future implementation.",Near,"This study could also be extended to explore benefits in the mining industry, when mine sites are retired, as AR could help companies ensure that the communities in the process of transitioning to different revenue sources have the tools that they need to ensure the sustainability of the land post-asset. Additionally the research methods could be extended or support other research programs associated with metals and mining, water preservation, education, policy, upskilling, and sustainability.",https://ec.europa.eu/research/participants/data/ref/h2020/wp/2018-2020/main/h2020-wp1820-energy_en.pdf[Crop preservation research recommendations] published by the European Union provide support for this research topic.,Jennifer Rogers,2021-08-31
18,Remote Plant Design and Onboarding with AR,"As research and development centers increasingly focus on implementing scalable industrial solutions on a global scale, it is difficult to ensure that, once new technologies are created and tested in a constrained environment, subject-matter experts can always travel to all the required plant locations.

Remote assistance or collaboration with AR-enhanced local technicians permits subject-matter experts to view a new installation and to support local staff with operation of new technology onsite. Remote experts may advise local users and, where necessary, support specific operational decisions that must be taken rapidly due to the specific site configuration and requirements (e.g. best equipment layout to drive operational efficiency, adjustments due to specific environmental requirements or regulations, etc.).

This research topic seeks to specifically measure time and cost benefits to new site operational readiness, as well as initial operational effectiveness, associated with AR- and non-AR assisted technology commercialization projects.

","Operational readiness, Operational effectiveness, Research and development, R&D, cost effectiveness, cost reduction, industrial research. technology, remote operations, decision support systems, failure, indicators, just in time, mixed realities, optimisation","Business, End User and User Experience, Use Cases","This research will provide operational excellence professionals, chief operating officers, safety and risk professionals, and plant managers quantitative information that will permit them to make better decisions about where and how to introduce AR in plants.","- Providing real-time support around decision-making associated with plant design and start-up via AR could decrease time to productivity and safe operational ramp-up.
- AR-enabled plant design systems could increase global commercialization of new technologies at a lower cost than traditional methods that rely heavily upon travel and availability of subject-matter experts and these experts must have familiarity with local languages, customs, and practices.
- Due to limited travel associated with COVID this is of particularly high interest, and could be of great significance to increased efforts to scale up vaccine manufacturing operations (and perhaps even distribution) across the globe.",The proposed research would need to identify key operational decisions and processes required for transfer from R&D to on-site operations. Research would measure time and cost to site operation with AR-assisted intervention and compare to known historical ramp-up times and costs.,Near,"This study could link closely with existing research programs associated with metals and mining, oil and gas, aerospace, manufacturing, and operational excellence in general.","Example of use cases:
https://www.cidrap.umn.edu/news-perspective/2021/02/who-pushes-covid-vaccine-production-scale-more-sharing +
https://apnews.com/press-release/pr-newswire/business-technology-lifestyle-products-and-services-jewelry-0c4c7956edd2d3f918f330a29ef59567 +",Jennifer Rogers,2021-08-31
19,"Cargo Container Loading, Inspection and Management with AR","Containers play an important role in the transportation of goods by sea and air. There are a variety of ways that AR can assist employees to track and manage containers on a vessel, airplane or in port. Where there are risks there are also opportunities. By having information about the status of containers, as well as the weight, shape and type of contents of containers in an AR-ready database, technicians can make better informed decisions.

An example of this is cold chain management. Containers with climate control are used to preserve and to extend and ensure the shelf life of products, such as fresh agricultural produce, frozen food, chemicals, and pharmaceutical products. Depending on the specific product, other physical parameters of the chain may also be regulated, (e.g. CO2/oxygen level, humidity and others).

Cold chain governance requires continuous monitoring and/or RFID tags to document the temperature history down to the container level. If a cold chain breaks, it is paramount to identify effected cargo as such and remove it from further shipping as soon as possible. Head mounted displays, or handheld devices can track unloading cargo and - pulling the data from the container’s data logger - visually identify non-compliant containers. This visualization allows for an efficient way of isolating non-compliance or other mismatches.

Stowage is another example. When loading merchant vessels, air cargo, or another shipping instrument, weight distribution is carefully calculated and loading is planned accordingly. These stowage plans are critical to vessel stability therefore compliance is very important. Although stowage or loading plans are delivered by various software tools, execution is dependent on human interaction.

Head mounted displays, handheld devices or stationary cameras can track loading cargo using computer vision, container marking (e.g. QR codes), RFID or other dedicated sensor networks. When loading is finished, cargo distribution can be projected on a digital representation of a vessel. This visualization allows for an efficient way to identify potential non-compliance or other mismatches leading to lower efficiency or risks.

This research topic focuses on documenting use cases for enriching the interactions that AR-enabled technicians, on board, during loading and in port, can have and decisions they may make when receiving and using accurate and up-to-date information about containers and their contents. As the professionals move about within and around containers when loading, inspecting, maintaining or repairing commercial containers, they will be more productive, and security and safety policy compliance can increase.

","marine, logistics, shipping, freight, cold chain, commercial shipping, containers, tracking, ships, cargo airplanes, technicians, port operations, cargo loading, inspection, safety, security, stowage plan, loading order, weight distribution, track and trace, sensors, data fusion, cargo, marine, ships, buoyancy, ambient intelligence, mechatronics, internet of things","Industries, Business, Technology","Operators of any cargo service including but not limited to shipping services, pilots, naval captains, shipping operations managers, quality managers, security managers, workers performing repair and maintenance on shipping containers, port operations, customs agents","- Many AREA customer segment members produce and distribute products globally. Some products are sensitive and must be shipped under controlled conditions.
- Other AREA members build and/or operate fleets of vessels (air, sea and land) and have operational responsibilities for the containers and their contents.
- AREA provider segment members producing software and display devices may wish to expand their offerings, based on precise use cases and requirements, in markets where the potential to impact safety, security and quality are high.","This research requires a team of experts intimately familiar with all aspects of the transportation of goods. The study of regional as well as global shipping patterns and technologies will be followed by development of prototypes and testing in a variety of settings. In field usability trials, with service professionals can reveal new requirements and opportunities for AR-assisted and IoT connected containers to reduce risk and increase productivity.",Medium,"This topic or theme of research overlaps with other topics pertaining to management of goods and services and use cases that benefit from users being able to quickly obtain information about any closed but connected container on land or sea. Research can be combined with assessments of accuracy at a distance from the target. The study of AR in commercial ports could have impacts on customs clearance and compliance with regulatory policy (e.g., safety, duties, etc).","Western Container Sales, a container retailer, https://westerncontainersales.com/augmented-reality-shipping-container/[offers AR experiences for prospective customers].","Christine Perey, Peter Orban",2021-08-31
20,Visualization of Anything of Interest Below Water Surface,"When conditions prevent visual scanning of environments and providing situational awareness using vision-based technologies, there need to be alternatives. The goal of this research is to provide users (decision makers such as operators of any boat or underwater craft) an accurate visualization of the real-time conditions of an operating (moving) machine (e.g., boat, submarine) when the visibility prevents reliable use of vision-based sensors.

Although identified/scored as a marine industry specific project, the scope of this topic is very broad and results could be applied in many industries. The topic spans everything from the use of non-visual sensors (e.g., sonar) for depth to the development of new computer-human interfaces for 3D data visualization.

","situational awareness, night vision, non-visual scanning in real time, marine, rescue, emergency response, autonomous underwater vehicles, marine navigation, marine radar","Industries, Technology","Developers, operators and owners/users of commercial, private or military water craft",- Almost all existing products for situational awareness rely on RGB or RGBD cameras for real time environment acquisition yet the visualization of obstacles or other salient features of the physical world are important and would serve as the basis for decision making for users when operating equipment in conditions unsuitable to vision-based sensors.,A research platform would be designed of lightweight and power efficient sensors that are effective as alternatives to cameras and existing vision-based environmental capture. The research would test and develop 3D interaction modes when a user's natural vision is impaired.,Medium,"This topic or theme of research overlap with the topic of visualizing conditions in the direction or on the path of any moving object. The outcomes of this research could also be applied in non-industrial use cases (e.g., scuba diving or other sports in low visibility conditions). The same research topic could be combined with study of user interfaces and interaction paradigms for the visually-impaired community.",None,Christine Perey,2021-08-31
21,Adoption of AR in Metals and Mining Value Chain,"As an industry that has thus far been slower to adapt to automation, mining finds itself at a crossroads with regards to the recent COVID pandemic, in that companies must redesign working environments to accommodate for the a) lack of available on-site skilled labor available to sustain current operations, b) mandates to reduce proximity of individuals, and thus number of crew members on site, and c) retraining and upskilling of current workforce as automation accelerates.

This research topic aims to describe the manner in which employment and crew models can be reconstructed to reduce risk to the overall mining value chain and preserve operational targets so as to prevent wide-scale economic impact to the world economy.

","metals and mining, employment, recovery, COVID, crew models, remote operations, risk reduction, human resources, metalworking, ore treatment,","Industries, Business, End User and User Experience","Economists, government officials in countries with heavy mining production, senior executives in metals/mining, HR professionals, social performance professionals, and operational excellence professionals will be impacted by this research.","- Mining is an industry that is incredibly important to the world economy and has been challenged greatly by the recent COVID pandemic. Lessons learned tell us that the industry needs to do a much better job of preparing for ""black swan"" events and the challenges that it presents to the entire mining value chain.
- By identifying crew models that reduce physical proximity and allow for reduction of risk across the mining value chain, many recommendations recently put forth by the Intergovernmental Forum on Mining, Minerals, Metals, and Sustainable Development can be immediately put into practice.",Survey key stakeholders to identify areas of opportunity within the categories of employment and areas of mining value chain represented on page 3 of the IGF report (https://www.iisd.org/system/files/publications/covid-19-employment-mining-en.pdf). Construct a series of AR-assisted employment models to drive specific improvement and employment resilience across the mining value chain.,Near,"This study potentially links to another proposed study around impact of AR on Multidimensional Poverty Index (MPI). This study could link closely with existing research programs associated with remote operations support and decision-making, as well as any programs around business impact and measures. It also relates to AR as an upskilling mechanism to assist with employment during increasing industry automation.","From the IGF report, ""Large-scale mining plays a critical economic and social role in remote areas. Large-scale mining activities are localized in remote areas with underdeveloped or few major alternative economic sectors. Mining plays a critical role for host communities, where it is often the largest—if not the sole—job creator and provider of vital services, including a variety of social services, such as health care and education. Large-scale mining creates more business in host countries. Mining activities have significant multiplier effects on the local and national economy through the creation of indirect and induced employment and business opportunities. ICMM3 estimates those opportunities can contribute up to 15% of national income in certain countries."" This https://www.iisd.org/system/files/publications/covid-19-employment-mining-en.pdf[IGF Study] describes the issues facing the industry that could be addressed in part with adoption of AR.",Jennifer Rogers,2021-08-31
22,Chemical and Radiation Sensors for AR Devices,"Existing AR display devices do not have sensors to detect gases, radiation or other elements in the user's environment. For many use cases of interest to the oil and gas industry as well as, mining, emergency responder and chemical industries, there needs to be research into the types and integration of existing chemical sensing technologies with the AR display or wearable computing system or to develop standard interfaces with IoT sensors to display readings in real time.

This research topic is a concrete example of a more fundamental research topic: the detection of an AR system user's context beyond what can be done with existing sensors (cameras, microphone, IMU, etc). The scope of this research can be narrow or large, depending on the support provided from commercial or public agencies.

","sensors, human factors, environment, oil and gas, chemical, power and energy, radiation, hazardous materials, radioactivity, explosives, chemical hazards,, volatile organic compounds, hazardous materials, aromatic compounds, gases, hydrocarbons, indicators (chemical), radioactivity, chemical hazards, chemical detection, gas sensors","Industries, Technology","Developers, operators and employees working in places where invisible gases may pose a risk, regulatory agencies, compliance officers","- Real time display of IoT sensor readings provide user context, beyond those that rely on RGB or RGBD cameras for real time environment acquisition.
- The lack of connection with sensors measuring gas or radiation represents a gap which can be addressed through research and could contribute to the development of standards.
- The visualization of gases and other salient chemical or radioactive features of the physical world are important and would serve as the basis for decision making for users when operating equipment in conditions unsuitable to vision-based sensors.",A laboratory would need to be developed for controlled exposure to chemicals and radiation sources. The lab and platform for testing will have off-the-shelf sensors and/or the project may require development of lightweight and power efficient sensors that are effective as alternatives to cameras and existing vision-based environmental capture. The testing and development of 3D interaction modes when user's environmental sensors detect unsafe conditions is a fundamental part of this research domain.,Medium,"This topic or theme of research overlap with the topic of visualizing conditions in the direction or on the path of any moving object in atmosphere that is opaque or under water. The outcomes of this research could also be applied in non-industrial use cases (e.g., pollution sensing). The same research topic could be combined with study of user interfaces and interaction paradigms for the visually-impaired community.","In 2012, the U.S. Department of Energy Office of Scientific and Technical Information (OSTI) funded research conducted at Department of Nuclear Engineering & Radiological Sciences, University of Michigan, on this topic. Preliminary results were reported in a https://www.osti.gov/servlets/purl/1405263[poster about visualization of radiation in AR].

A https://indico.cern.ch/event/717796/contributions/2949592/attachments/1715219/2766824/PresentationGoriniSchool_MeasurementsForRobotics.pdf[2017 presentation about research on related topics conducted at CERN] using HoloLens in particle accelerator environments is also relevant.",Christine Perey,2021-08-31
23,Reconciling Discrepancies between Documented and Actual Locations of Pipeline Networks,"Municipal water systems can be major beneficiaries of Digital Water Services: a combination of source monitoring, production and quality management, leak detection, water balance and network monitoring/modeling and process control. In order to be able to deploy these services at large scale and low cost, the first step is to create a digital representation of the pipeline network. However, documentation of pipeline networks are not always kept up-to-date, or sufficiently precise, therefore, said documentation must be validated or corrected by physical, on-site measurement and documentation.

Largely a manual process of measurement and photographic documentation, this first step represents significant time and human resource investment and is prone to errors. Head-mounted AR displays equipped with camera systems, SLAM (TOFL/LiDAR) and GPS sensors could speed up the process of documenting pipeline networks by performing volumetric capture of the exposed water network assets and interpolating the underground portions. Using the latest camera technologies on AR devices can validate geographic and dimensional data while eliminating or reducing errors.

This research explores the use of AR devices mounted with different camera and SLAM sensory systems using manual measurements as a baseline. The focus is not on end users but on the rapid and accurate capture of data about existing infrastructure.

","volumetric capture, utility asset management, digital water services, predictive water sources management, water supply, water treatment, well stimulation, well testing","Industries, Technology, Use Cases","This research will be valuable to the operators of municipal water systems, waste management systems and the IT managers, field work force, and partners performing maintenance and repairs of utilities infrastructure.","- Some AREA members build, operate and manage large public and private infrastructure for clean and waste water.
- Systemic loss in water networks ranges from 20-90% (globally). Improving the digital representation of these systems with accurate and automatic measurement technologies will reduce costs of measurement and over time, resource loss, and create a more sustainable water management system.","Initial lab testing of various volumetric capture solutions will evaluate candidate solutions, followed by in-field test comparing said solutions with physical ground truth. This will be supported by test of various data extraction methodologies.",Medium,"Leakage and issues with obstructed pipes are not unique to water utilities. The research techniques developed for this topic can be adapted for use in other types of utilities and industries where resources are sent using linear assets and infrastructure. The research platform could be commercialized into products or services to increase safety, reduce waste and optimize operations of infrastructure.","In October 2019, research about an subset of this topic https://www.researchgate.net/publication/336238139_DEVELOPMENT_OF_AUGMENTED_REALITY_PIPELINE_VISUALISER_ARPV_APPLICATION_FOR_VISUALISING_UNDERGROUND_WATER_PIPELINE[has been published in the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences].","Peter Orban, Christine Perey",2021-08-31
24,Visualizing Water Flow and Quality in Municipal Water Networks,"Most municipal water supply pipe networks require a manual operation of various control units in case of scheduled maintenance or an emergency. Crews operating gate valves to isolate sections of the network greatly benefit from updated information on the flow and quality of the water in these sections.

This research topic includes a field test of handheld or wearable devices to aid technicians in the field to visualize water flow and water quality data received from the control center. The user's device also could be connected to the control room, or substations, where there are multiple water pipes and sensor stations to view. The scope of the research could include the visualization of interfaces for gate valves and other equipment in the field.

","Data visualization, decision support, utility asset management, digital water services,, water supply, water treatment, well stimulation, well testing","Industries, Technology, Use Cases","This research will be valuable to the operators of municipal or regional water systems, waste management systems and the IT managers, field work force, and partners performing maintenance and repairs of utilities infrastructure.","- Some AREA members build, operate and manage large public and private infrastructure for clean and waste water. Systemic loss in water networks ranges from 20-90% (globally).
- Improving the digital representation of these systems with accurate and automatic measurement technologies will reduce loss and create a more sustainable water management system.","To model and visualize the behavior of liquid inside the pipeline, computational fluid dynamic simulations will be employed. Using areas that have reliable, manually measured flow parameters, the AR-enabled prototype system will be tested in the field. Various data extraction methodologies are used to compare the AR-assisted platforms with ground truth.",Medium,"Leakage and issues with obstructed pipes are not unique to utilities. The research techniques developed for this topic can be adapted for use in other industries where resources are sent using linear assets and infrastructure. The research platform could be commercialized into products or services to increase safety, reduce waste and optimize operations of infrastructure.",None,"Peter Orban, Christine Perey",2021-08-31
25,Using 3D and World Mapping Standards to Streamline AR Experience Production,"Creating AR experiences using existing authoring environments is a time-consuming process even for highly-trained developers. One of the greatest hurdles is the specification of real world features to which AR assets are attached/anchored. An alternative to manually defining anchors for AR assets is to adapt the outputs of real world 3D capture systems used in enterprises to be used as anchors for AR.

New interfaces and data encodings for 3D capture systems to make those systems directly accessible in an AR authoring pipeline will streamline or automate the preparation of AR experiences based in part on 3D capture of enterprise environments. However, there are many different 3D capture systems. This research topic focuses on development of guidelines and/or standards that will define the formats for 3D real world mapping which can be used by commercial AR authoring platform developers and publishers.

","3D world capture, depth sensing, liDAR, AR experience authoring, AR assets, anchoring, world mapping, SLAM, simultaneous localization and mapping, standards, data preparation, object-oriented programming, open systems, authoring systems, shape recognition, feature extraction, 3d modeling","Standards, Technology","This research is relevant to AR experience developers, AR managers, AR authoring platform publishing companies, AR service providers,","- This research will provide AREA members and their technology providers insights into how standards used in real world capture may streamline AR authoring pipelines.
- If AR authoring can be semi or fully-automated this will reduce costs, time and errors that are inherent when humans are required to custom engineer AR experiences.","Requirements for this approach for authoring AR experiences will be compared with existing and new standards and/or extensions of existing standards to automate AR authoring. The gaps and requirements will more easily be provided to appropriate standards development organizations for future work. If and when new interfaces and standards are published, enterprise AR authoring software vendors will be able to use these to streamline the AR authoring pipelines in industry.",Near,"This topic could be combined with other topics to increase efficiencies in AR asset and experience authoring, management and delivery to reduce time and costs of integration with existing authoring and data management systems and platforms.",This topic was submitted for 8th and 9th AREA research projects and received high support.,Christine Perey,2021-08-31
26,Automated Alert to Dangerous Workplace Conditions,"Many industries require that employees work in high risk environments. For this reason, employees are certified in advance of performing tasks and follow very strict protocols. When sensors on a device or during a work flow detect that a high risk or dangerous setting or task is imminent, there needs to be an automatically-displayed alert. Research that increases the reliability of automatic risk assessment based on situational awareness from employee-worn sensors, regardless of the technology provider, and produces a consistent and clear response regardless of the AR device model, mode or connection state would provide value to those working in high risk industries.

This research topic will extend the user experiences that are currently provided on smartphones in the workplace. It will also need to clarify when and how existing alert systems prioritize the messaging to users and test usability and benefit of having the alerts appear in AR view.

","safety, risk, automated alert, standards, situational awareness, sensors for risk detection, artificial intelligence, health risks, occupational risks, risk assessment, risk perception, accidents, safety-critical software, occupational health, occupational safety, safety, accident prevention, disaster prevention, electrical safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Standards, Technology","Standards bodies, Safety officers, employees working in high risk jobs","- Saving lives and reducing risk to which employees are exposed is a high priority and represents a significant cost to operations.
- Reducing the risk through technology use brings immediate return on investments, in many industries.
- The specification of AI systems connected to AR displays for risk detection, and the sequence of triggers leading to an alert being provided to the user, is valuable regardless of the manufacturer of the sensors or AR display.","This topic requires consensus building by working with safety officers, and new approaches to create and codify use of AI (and train the AI) to detect high risk context and circumstances, and to immediately alert the AR user. The research could also study different types of alerts for different industries, their effectiveness and recommend protocols that all devices and AR-based systems could adopt.",Near,"This topic or theme of research overlaps with the topic of visualizing alerts in a timely, intuitive and meaningful way. The outcomes of this research could also be applied in many industries. It could be combined with topics pertaining to safety and human factors.",Could be an offshoot of UL8400 or BSI IST/31.,Christine Perey,2021-08-31
27,Common APIs for Tracking Libraries for Vision-based AR,"Tracking and registering the position and orientation of the user's camera in real-time is a fundamental functionality for Augmented Reality. For enterprise use cases, the environment cannot always have markers for tracking. There are vision-based tracking libraries using markers and natural feature recognition technologies available as open source libraries as well as under license from commercial sources. In the future, there will likely be many tracking libraries, each optimized for specific contexts and tasks.

When designing AR experiences, developers using existing AR authoring platforms are either forced to use the publisher's own tracking library, or, under the best of circumstances, may choose tracking libraries which will be compiled into the final experience. The developer's choice will depend on the use case requirements. However, when authoring AR experiences, the developer does not have full control or perfect knowledge (for training purposes) of all the environments and features that will be in the user camera's field of view.

As AR experiences become more complex and suitable for use in more environments and circumstances, the AR developer may need to provide (to include or offer) multiple tracking libraries, each suited to the phase of a process or the setting of the user when performing tasks.

This research topic will explore requirements of AR experiences and the attributes of common and future tracking libraries for AR and, based on use cases and requirements, develop one or more application programming interfaces that can be implemented and submitted to an appropriate organization for standardization.

","application programming interface, APIs, Tracking Library, AR Experience Software, Interoperability, Multi-Library support,, Interoperability, application programming interface (api)","Standards, Technology","Standards bodies, end users, AR experience developers, AR authoring platform publishers, AR tracking library developers, computer vision scientists and developers","- AR experience developers and the users of those are unable to specify all future use conditions. If and when conditions change in user contexts or tasks, or new vision tracking libraries are published, the process of changing libraries requires returning to the beginning of the authoring.
- The proposed research and resulting standard would make it possible for developers to switch between different libraries quickly, perhaps automatically, and with confidence that the libraries are available when needed.",The research will focus on tracking library characteristics and the authoring platforms. There will also need to be study of run-time systems for analyzing the real world features and matching the tracking library with the user contexts for the AR experiences to be provided. The research will also require working with open and consensus-based Standards Development processes.,Medium,"This research topic could be part of a program developing more ""fine tuned"" tracking libraries for specific enterprise workplaces, environments and tasks. The results would also benefit non-enterprise users who also change their needs and use cases without wanting to download new or update their AR experiences.",API development for more flexible architectures when authoring with or using vision-based tracking libraries was proposed as an AREA-directed research project topic in January 2020.,Christine Perey,2021-08-31
28,Capture and Reporting of Hazardous Incidents in Augmented Reality,"In many industries, corporate, public or industry policies require documenting the circumstances of a hazardous incident and steps taken by an individual or group to reduce or eliminate risks to equipment, employees or others. In order to comply with such policies, it is valuable to have user-worn (user perspective) recording systems automatically triggered and the observations of all sensors encrypted for secure reporting. In some circumstances, a user can self-report incidents by completing an AR-enhanced report form through gestures and auditory commands which are then uploaded and recorded, possibly disseminated to appropriate functions within the organization for corrective actions (Facilities, EHS, etc.)

Alternatively, a constant recording buffer on a user device could be implemented. This could be paired with an artificial intelligence to recognize incidents and/or corrective actions. This may automatically default to an on-premise/centralized or cloud-based management system. For there to be consistent and compliant recording and reporting, AR devices could comply with a capture trigger specification, a capture and encryption protocol and, perhaps, produce reports in standard formats that are acceptable for regulatory and compliance tracing.

This research topic contributes technical requirements and potential solutions to be submitted for standardization in one or more bodies for the purpose of reducing the complexity of integrating AR-assisted automatic incident capture into the IT infrastructure of appropriate authorities.

The topic includes definition of automatic AR-assisted or enabled capture technology types suitable for hazardous incident reporting, resolutions of and compression rates for video and audio, data types to be captured (e.g., location data, temporal parameters, identities of nearby people and other), local and remote security to comply with anti-tampering precautions, and other relevant parameters, regardless of the maker of the AR display devices used.

","Standards requirements, standard specifications, hazard management, risk management, safety management, data capture, data integration, data encryption, cybersecurity, occupational risks, risk assessment, risk perception, accidents, occupational health, occupational safety, safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Standards, Technology","Standards bodies, risk managers, safety managers, policy managers, AR developers, IT developers, designers and manufacturers of enterprise AR displays would benefit from there being standards developed in this domain.","- Some risk sensitive industries and companies require capturing and reporting any incidents that occur in the workplace. Having AR-assisted capture and reporting would reduce cost of compliance.
- AREA members are deploying many different models of AR display devices from numerous display manufacturers. The complexity and cost of integrating hazardous incident capture and reporting technologies with each device in the workplace is prohibitively high.
- A standard with which all devices must comply to be used in workplace settings will increase adoption of AR-assisted capture and reporting of hazardous incidents, increase compliance to policy and reduce cost of implementation of software and integration of AR with enterprise-defined or industry regulated norms.","The topic requires definition of requirements for automatic, real time, user-perspective, tamper-resistant capture technology that documents situations, user actions and other relevant parameters for compliance purposes. Requirements must then be codified into specifications following industry norms and consensus of group members.",Medium,"This research topic can be combined with industry-specific research projects such as the development of body-worn cameras by law enforcement officers. It can also be an extension to cybersecurity research, research about media encryption and standards pertaining to other methods of incident reporting.",Could be an offshoot of UL8400 or BSI IST/31,Christine Perey,2021-08-31
29,Systems Integration between PLM Systems and AR,"Significant AR experience development effort and time is dedicated to linking domain-specific data to AR engines and presentation systems. While many industries invest in AR scene development, the need is especially high in the manufacturing industry. Product Lifecycle Management (PLM) software systems curate design, manufacturing, and sustainment information related to a product system (ideally) throughout its entire lifecycle.

Leveraging such data across PLM systems for industrial AR has mainly become a platform-specific exercise. Commercial PLM software vendors provide industrial AR solutions that leverage their application programming interfaces (APIs) to help establish AR scenes. However, most large original equipment manufacturers (OEMs) operate in complex, global, and heavily distributed supply chains. In other words, in many cases, OEMs subscribe to every major commercial PLM software platform to handle the variety of data representations provided by their suppliers. This is especially important if the developers aim to truly create a digital twin of a product or production system.

This research topic will develop and test a standard data model that permits the vendor-neutral exchange of AR-critical data to produce updatable, sustainable, and maintainable AR scenes. One particular area of interest is understanding the proper handling of industrial animations.  Though AR standards provide representations for presenting animations within AR scenes, for example, they do not directly relate to product system animations stored within PLM systems. Rather than relying on a particular PLM platform's data representations, if such a data model was successfully developed, software developers would be able to exchange data across PLM software and to platform-agnostic AR engines more readily.

","standards, data interoperability, digital twin, product lifecycle management, platform-agnostic AR solutions, application programming interfaces, distributed supply chains, manufacturing, sustainment, industrial Internet of Things, IIoT, ontologies (artificial intelligence), cost engineering, knowledge engineering, information management, project management, supply chains, team working, asset management, metadata, application programming interfaces, open source software, design engineering, systems engineering, cad/cam, quality management, supply chain management, manufacturing industries, product life cycle management, standardization, interoperability","Standards, Technology, Industries","OEM manufacturers, integrated solution and software developers, CAD/CAM providers, engineering design teams, PLM software publishers","- Product design and manufacturing is the focus of many AREA customer segment members.
- Resources invested in connecting domain-specific models, such as those stored with PLM systems, to proprietary AR engines and presentation systems increase cost and the time to reaching positive RoI on AR investments in manufacturing. - If a standard data model to represent AR-related data in manufacturing for use in PLM were adopted, systems integrators would increase use of AR in their solutions and members would have lower risk and investment to re-use existing or new engineering assets in AR experience.",This research topics could focus on testing existing PLM platforms and their AR-related competencies.  Reporting on gaps bewteen the interfaces across related software tools will be a strong contribution. Existing standard data representations provide a strong starting point for investigation. Focusing on dealing with sustainment for digital twin models would cover lots of the use cases.,Near,"OEMs with complex and heavily distributed supply chains should be a center point for the project. Program managers and technical advisors in such organizations understand the issue of cumbersome technical data packages.  This research topic significantly overlaps with https://github.com/theareaorg/AREA-Research-Agenda/blob/main/AREA_Research_Agenda_2021/Categories_and_Topics/Research_Topics/SInteroperability3-digialmodels.adoc[the Digital Model Interoperability research topic]. [BB: issue with sentence grammar] There are distinct in that this research topic is specific to the manufacturing industry. The https://github.com/theareaorg/AREA-Research-Agenda/blob/main/AREA_Research_Agenda_2021/Categories_and_Topics/Research_Topics/SInteroperability3-digialmodels.adoc[Digital Model Interoperability research topic] relates more generally to 3D asset translation and can be applied to other domains, such as construction.","There exist resources to help position research efforts.  For example, the https://www.cax-if.org/[CAx Implementor Forum] provides a number of test cases. The Khronos Group is continously updating https://www.khronos.org/gltf/[glTF], the latest de-facto standard for lightweight model presentation. https://www.asme.org/topics-resources/content/y14-standards-overview[ASME Y14] is a working group that focuses on the standard presentaiton of GD&T annotations.",Bill Bernstein,2021-08-31
30,Harmonization of Standard Industrial Data with Lightweight 3D Models,"Computer-aided design (CAD) platforms provide a broad suite of tools for constructing highly precise digital three-dimensional (3D) representations of parts, assemblies, and structures. Many engineering teams and organizations adhere to a single CAD platform for formally representing geometric dimensioning and tolerancing (GD&T) requirements, optimizing design performance through detailed simulations, and developing initial process plans for manufacturing the parts. With the increasing emphasis on model-based engineering across industry, more value is embedded in these digital models every day.

To allow for native 3D models to be displayed on AR modalities, model translation is necessary into more efficient digital models.  Previous work has focused on model tessellation and decimation to make sure that the models are perceptually accurate. Inherently, there is a loss in geometry and topology precision in the translation process.  However, for most AR use cases, there is no need for such a high level of accuracy in the presentation of part and assembly geometries. These translation methods do not currently port supporting information, such as GD&T and other Product Manufacturing Information (PMI), in a platform-agnostic manner.

There is a research opportunity for leveraging existing industrial data standards that enable the exchange of part and assembly information with limited loss of information.  One particular use case of interest is dealing with engineering change management.  In theory, model-based engineering facilitates better management of engineering change, as the native CAD model serves as a reference for all product lifecycle functions and processes.  Let's consider assembly animations and their use in a AR-assisted assembly workstation.  If there is a persistent link or pipeline between the native 3D models and animation with the tessellated model to be used in XR, theoretically, the AR-assisted workstation could be agile and updatable based on upstream engineering changes.

Additional work is required in fundamental mappings between standard data representations, both from the domain perspective such as manufacturing and the AR standard community such as glTF animations.  In general, such work has been characterized as standards harmonization.

","digital enterprise, model translation, interoperability, product manufacturing information, geometric dimensioning and tolerancing, assembly animation, engineering change management, updatable AR, maintainable AR, transferrable AR, agile AR, knowledge representation, ontologies (artificial intelligence), information management, production planning, metadata, application programming interfaces, systems engineering, cad/cam, cad, computer aided design, integration, industry 4.0, 3d modeling, assembly, manufacturing data processing, product life cycle management, computer aided engineering, Interoperability, standardization, protocols","Standards, Technology, Industries","OEM manufacturers, integrated solution and software developers, CAD/CAM providers, engineering design teams","- Translations of 3D models consumes significant time and resources.
- If better tools existed for translating native models into AR-ready representations, industrial end-users would benefit directly.
- The strong design and manufacturing focus of the AREA sit at the center of this potential research area's benefits.",Existing model translators and standard data representations provide a strong starting point for investigation. Focusing on handling PMI and properly spatially anchoring them in the tessellated model would be a good choice for an initial project.,Near,"This topic would directly benefit construction and manufacturing industries.  Luckily, lots of the existing domain-specific standards cut across these two industries. Working together to develop application domain extensions for AR standards would be a good first step.  This research topic significantly overlaps with https://github.com/theareaorg/AREA-Research-Agenda/blob/main/AREA_Research_Agenda_2021/Categories_and_Topics/Research_Topics/BIntegration3-ar2plm.adoc[the AR to PLM research topic].  There are distinct in that this research topic is specific to the manufacturing industry.  The other research topic relates to developing a standard data model for ingesting PLM data, such as sustainment data for maintaining digital twins.","There exist resources to help position research efforts.  For example, the https://www.cax-if.org/[CAx Implementor Forum] provides a number of test cases. The Khronos Group is continously updating https://www.khronos.org/gltf/[glTF], the latest de-facto standard for lightweight model presentation. https://www.asme.org/topics-resources/content/y14-standards-overview[ASME Y14] is a working group that focuses on the standard presentaiton of GD&T annotations.",Bill Bernstein,2021-08-31
31,Testing Protocols for AR-assisted Human-Robot Interaction,"In terms of collaborative robotics, the widespread adoption of robots in historically manual manufacturing environments (which are subject to high product turnover, short production runs, and high variability in equipment configurations) is limited by the robots’ inability to effectively and safely integrate and interact with the existing human labor.  Instead, so-called collaborative robots are relegated to secluded operations with minimal contact with the workforce.  The robots’ inability to communicate with, understand the intention of, and establish a mutual understanding of the environment and situation with human coworkers decreases the robots’ usefulness in collaborative teams consisting of both robots and people.  This limitation is driven by both the absence of tools and protocols needed for effectively describing and measuring human-robot interactions, an incomplete collection of metrics for assessing human-robot teaming performance, and insufficient protocols for enabling more intuitive interfacing with robotic tools. These challenges are compoudned when augmented reality technologies are used at the interface between the robotics and human workers.

This research topic focuses on providing the methods, protocols, and metrics necessary to evaluate the interactive and teaming capabilities of robot systems. It uses a task-driven decomposition of manufacturing processes to assess and assure the safety and effectiveness of human-robot collaborative teams.

","robotics, human-robot interaction, human-computer interaction, remote monitoring, remote control, collaborative robots, autonomous agents, communication, computer vision, control systems, cooperative systems, grippers, human factors, human-robot interaction, industrial robots,	industry 4.0, intelligent robots, multi-robot systems, occupational safety, robotics, safety","Standards, Technology, End User and User Experience",Manufacturers will benefit from the products generated as a result from this research project.  Robotics providers can also benefit in that standard testing protocols for human-robot interaction will generate new sales tactics. End users will benefit in that the end state will be much safer in complex manufacturing environments.,"- Robotics are pervasive in manufacturing, a key area for many AREA members.
- However, safety concerns in collaborative robotics scenarios have curbed overall use.
- AR-enabled communication between humans and robots can create a much safer environment.","This collection of methods, protocols, and metrics will enable integrators and end-users to maximize the effectiveness and efficiency of collaborative human-robot teams in production processes, impacting both large-scale companies designing and repurposing hybrid manufacturing workflows, and smaller companies looking to begin introducing automated tools into manual processes.",Long,"This research topic mirrors https://www.nist.gov/programs-projects/performance-human-robot-interaction[an existing project at NIST]. Inspiration can be driven from the existing work generated by that team. Furthermore, IEEE is a leader in curating academic work in this area. Refer to https://www.ieee-ras.org/conferences-workshops[IEEE RAS] for related publication venues, including https://www.ieee-ras.org/conferences-workshops/fully-sponsored/case[IEEE CASE], https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra[IEEE ICRA], and https://www.ieee-ras.org/conferences-workshops/financially-co-sponsored/iros[IEEE IROS].","This topic requires significant hardware, middleware, and software integration. One open source framework is https://rosindustrial.org/[ROS-Industrial]",Bill Bernstein,2021-08-31
32,Trade-off and Substitution: Stereoscopic Vision for Spatial Audio,"Stereoscopic vision has long been considered the best type of visualization in terms of matching physical and simulated realities. While stereoscopic vision is the goal, producing a perfect 3D visualization and registration of AR assets is difficult using current technologies. Addressing the shortcomings of current AR displays will be prohibitively high and present a financial barrier to AR adoption in enterprises.

Leveraging advancements in Digital Signal Processing (DSP) and audiology, a new class of devices are emerging. Spatially-aware audio transducers can help determine the exact position and posture/pose of the wearer as well as generate a simulated sound field that matches the physical environment. Such systems could be combined with existing vision-centric displays for high fidelity enterprise AR experiences.

The scope of this topic includes measurement of the spatial audio technology resource requirements and impacts of combining visual cues with spatial audio on user performance. Comparative studies of human cognitive performance aided by varying blends of spatial technology ranging from “audio-only” to “video-only” and various combinations of both are also in scope.

","spatial audio, effectiveness, spatial vision, 3D audio, perception, audio signal processing, acoustic waves, active noise control","Technology, End User and User Experience, Displays","AR experience designers, developers of integrated sensor and world capture components, human factors researchers","Spatial vision is not always as practical, comfortable or affordable way to produce AR experiences that help reach use case objectives.
- If performance requirements on vision-based AR delivery can be reduced using spatial audio components or solutions, enterprises may have more options and greater flexibility when sourcing their AR experience delivery devices.
- Adopting spatial audio-based solutions may lower total resourcing needs, reducing the financial barriers of enterprise adoption.
- Spatial audio may also increase the impact of AR experiences in which there is possibility of visual AR interference or occlusion of the user's vision.","This research topic will require development of visual and audio AR experiences to be produced in a highly controlled laboratory environment within which a series of experiments can be conducted and reproduced. Studies will compare spatial audio requirements to vision-only AR experiences on the basis of accuracy, speed, battery life, bandwidth requirements, processor performance, wearer comfort and pricing. In addition to user perception assessments through surveys and interviews, methods could be expanded to include time-motion studies using standardized, public and well-documented processes typical of industry verticals, use cases and horizontal use case categories.",Medium,"This topic is at the intersection of both 3D visualization and 3D audio. The methodologies and tools developed for this research could be used in the study of perception, presence, and lead to new guidelines for AR developers and manufacturers of HMDs for enterprise AR.","In 2016, the Sound of Vision consortium, which focuses on the construction of a new prototype electronic travel aids for the blind https://www.researchgate.net/publication/304822071_Sound_of_Vision_-_Spatial_Audio_Output_and_Sonification_Approaches[published a report] about audio-assisted vision.

A peer-reviewed article http://www.aes.org/e-lib/browse.cfm?elib=15891[presenting a novel technique for reproducing coherent audio visual images for multiple users], only wearing 3D glasses and without utilizing head tracking was published in 2011 in the Journal of The Audio Engineering Society.","Peter Orban, Christine Perey",2021-08-31
33,Biometric Identification of Wearable Enterprise AR Device Users,"New AR display devices encounter significant resistance from enterprise IT teams who consider the new hardware platforms increase security threats, consequently, increasing the need for an elevated security posture.

Driven by a human-centric approach, a critical step in ensuring compliance with existing security policies and systems is to balance the security with accurate and rapid user authentication and ultra-low-friction user input.

Biometric identification methods, ranging from palm-prints, voice-prints, iris scanning, gait to heartbeat detection offer a plethora of opportunities for identification of wearable enterprise AR device users before providing access to enterprise work orders and data.

This research topic compares different modalities of biometric identification and classifies them based on accuracy, cost and ease-of-use.

","biometric, palm print, voice print, gait, retina scanning, iris scanning, heartbeat detection, skin conductivity, access control, data protection, security systems, authentication, message authentication, authorization, data security, access protocols","Displays, End User and User Experience, Technology","All stakeholder in corporate security organizations but primarily CISOs, CIOs, IT and security managers. On the vendor side, OEMs, solutions providers, system integrators and independent software vendors will be impacted by this research.","- Securing endpoints in the enterprise is a critical step in preventing compromised security of enterprise systems.
- Highly personal modalities of authentication raise legitimate authentication, human factors and privacy concerns.
- Implementing best practices reduce the negative impacts of slow and unreliable user authentication and inputs.","This research will require rigorous laboratory tests, deployed via multiple cells of different modalities. This will be followed by human factors and security research, culminating in field trials. Once baselines are available and validated, best practices can be established.",Medium,"This topic is closely related to another proposed AREA Research Agenda topic on cleaning and authenticating multi-user devices end user [ra-Tsecurity5-multiuserdisplays]. The topics could be combined with other AR security topics to develop a broader research program. In addition, the topic could be expanded to use the sensors on devices of other AR users in a workplace to confirm user identities.",The field of biometric authentication in cybersecurity is vast and there are many highly reputable research centers that could contribute to this research. Hundreds of publications appear each year in journals and proceedings. https://www.heinz.cmu.edu/~acquisti/papers/AcquistiGrossStutzman-JPC-2014.pdf[This paper describes results of studies to connect AR users with sensitive personal information derived from on-line platforms and use of these data to predict AR user interests and preferences.] In the https://dl.acm.org/doi/proceedings/10.1145/3457339[proceedings of the 7th ACM on Cyber-Physical System Security Workshop] (May 2021) https://dl.acm.org/doi/pdf/10.1145/3457339.3457983[an article compiles recently published work on this topic and describes MoveAR.] The goal of MoveAR is to distinguish between a legitimate user and potential adversaries based on the signatures detected by the on-device sensors as the user interacts with an augmented reality environment.,Peter Orban,2021-08-31
34,Authoritative Information and Source Validation in AR,"In many use cases and network architectures, data requested by and provided to an AR user for an experience is not pre-loaded on the users device. For a variety of reasons and through a range of technologies, information is streaming from the cloud or edge to the AR device in real time. The reverse is also happening. Sensors on an AR user's device are capturing the real world and can send during or after world capture salient features or any combination of data (e.g., point clouds, video, audio, etc) to a safe and high capacity storage resource in the cloud or on the edge. Users may also need to use an AR device to annotate, confirm ground truth or add information about the real world to the cloud-based databases. During data creation (annotation) or transfer, there may be opportunities for agents to insert inaccurate or false information, or for corruption.

Depending on use cases or publishers, the level of confidence about accuracy and authorship of information consumed from or added to a remote source will vary. In enterprise or industrial use cases, details about asset authenticity, ownership or conditions for use must be associated with the AR asset in metadata.

This research topic focuses on development of ontologies, protocols and/or standards to ensure and to  communicate to or between enterprise systems and users in workplaces that data delivered for use in AR experiences is from an authorized source. In parallel, the research will study or develop on-device authentication systems to validate that data which is added to a pooled (cloud-based) data repository during an AR experience (e.g. tagging information and placing information) is authoritative and the source traceable.

","data capture, data streaming, security, authentication, author, authorship, publication, ownership, remote data repositories, AR cloud, edge computing, spatial computing, access control, data protection, security systems,  authentication, message authentication, authorization, data security, access protocols",Technology,"Network operators, network managers, enterprise IT managers, AR experience publishers, AR experience authoring platforms, AR developers","- Before introducing data from remote sources to users in their networks or from users' AR devices into their data management systems, AREA member organizations must ensure that the data source is authenticated and any metadata associated with it can be used regardless of the choice of display or data architectures.
- The members need to better understand the potential risks and opportunities of introducing AR Cloud for real world capture and data delivery in enterprise networks.",The research will focus on device encoding and edge computing technologies from multiple suppliers that can support distributed AR architectures. Studies will evaluate use of encryption and authentication technologies on device for suitability in distributed computing. Laboratory-based studies in controlled environments will measure and compare different approaches to data authentication and metadata authoring.,Medium,"This research topic could be part of a program studying the potential benefits of AR Cloud and 5G networks which provide low-latency and high bandwidth connectivity between cloud, edge and AR devices. Other topics such as cloud-based rendering of 3D graphics, discovery of AR experiences and security could be combined with this topic.","There is work in the W3C, IETF, IEEE, OMG and other standards bodies on related topics that could contribute to development of best practices and standards for enterprise data management systems.",Christine Perey,2021-08-31
35,Automatic Detection and Obfuscation of Facial and/or Personal Data of People in AR User Vicinity,"In or in proximity of an AR-enabled user's workplace, and in the field of view of the AR display's camera, there may be people who have not agreed to (or are not able to grant permission for) their facial features or any personal data to be included in the AR system's live video stream. If the private information of a person is captured without their explicit permission, a company may be held responsible for storing and any future use of the data. To reduce potential liabilities, entities responsible for a workplace will seek to implement a component of an AR display that removes all unrecognized faces from their systems.

This research topic includes using automatic detection of faces in an AR camera's field of view, determining if the detected facial features are among those of people who have granted their permission to be tracked, and if the face does not match any in the database of those who have granted permission, to automatically and continuously obfuscate the features.

","face detection, facial identification, obfuscation of region of interest, personal information, privacy, privacy protection, security, compliance, biometrics, data security, access protocols","Technology, End User and User Experience, Business","All stakeholders in corporate security organizations including but not limited to privacy managers, workplace policy managers and risk managers. In order for obfuscation to be implemented in commercial systems, the research would need to take into account the requirements of the AR display ecosystem players (e.g., OEMs, solutions providers, system integrators and independent software vendors) who could leverage the results.","- Employees of AREA member companies may use their AR-enabled systems, including cameras and microphones, in public spaces or in the presence of customers, employees of partner organizations or elsewhere that are not in their exclusive control.
- If an employee is using an AR device in the presence of people who have not granted permission for their personal information, including but not limited to facial features, to be stored and used by the company, the company may be exposed to penalties for breaching privacy data protection regulations.
- Technology components that remove or reduce this type of risk will increase compliance without the user's needing to take action or interrupt the processes they are following to perform a task.","The research will identify and evaluate automatic facial detection and identification technologies for suitability on an AR display. This may include assessment of speed, reliability and computational complexity. Computer vision solutions that meet requirements will need to be compared and tested to ensure that they do not reduce display performance or ability to meet the requirements of the user's primary AR use cases.

This topic may also involve introducing systems that interrupt an AR-assisted process and prompt a user to change orientations and/or ask unauthorized people to move out of camera view.",Medium,"This topic can be combined with the study of automatic detection and management of other sensitive data types. For example, the license plates of cars, names of people appearing in semi-public places (e.g. postal box), and voices of people in proximity of the AR-enabled user could be selectively removed based on the local regulations and privacy policies. It could also be combined with the research [ra-Tauthentication5-biometric][on biometric authentication for AR display users].",A 2014 peer-reviewed paper https://www.researchgate.net/publication/323372332_Face_Recognition_and_Privacy_in_the_Age_of_Augmented_Reality[describes tests performed and highlights the implications of the convergence of face recognition technology and use of AR].,Christine Perey,2021-08-31
36,Cybersecurity Risk Assessment and Reduction for AR Environments,"Sensitive enterprise or customer data could be exposed to threats from hostile actors when in field of view of AR-enabled cameras, and/or when sent to users' AR device in order to support their task performance. The hostile actors may interfere with transmission of sensitive data, interrupt or distort its presentation to the user in the AR display, or could operate without detection while ""scraping"" enterprise or customer data for other users. Cybersecurity threat identification and assessment, and mitigation measures for those managing the AR displays in a company are critical to integration of AR in mission critical environments and need to be studied.

Approaches to reducing risk and increasing resilience of AR display devices can be tested and industry guidelines and best practices published by and for cybersecurity experts. The scope of the research could include comparisons of device vs wireless network security.

","Cybersecurity, risk, encryption, distributed ledger technologies, integration, data interception, network security, security of data, computer crime, computer network security, computer privacy, cryptographic protocols, fraud, intrusion detection, data protection, blockchain, access control","Technology, Business","Data security officers, employees working in highly sensitive disciplines, customer data protection, employees using AR in the field to access secure databases,","- Enterprises cannot integrate and deploy technologies that introduce risk to their intellectual property or customer data.
- As long as their data is at risk of exposure, security experts will prevent AR adoption in domains or workplaces where there is uncertainty or risk of exposure.
- Very little is known or documented about possible impacts of the issues around this topic. Studies of enterprise implementations of cybersecurity programs or software in conjunction with AR will increase awareness of issues and reduce risks.","This project will require laboratory or bench studies with cybersecurity threats into commercial wearable AR displays will highlight vulnerabilities. Tests of commercial or experimental software to manage sensitive data can be conducted in simulated environments. Further, after the tests in simulation, there should be research on the use of the threat mitigation systems in live environments.",Medium,"This topic or theme of research can be combined with assessments of geofencing, biomarkers for user authentication and other methods to reduce risks to enterprise data.","In 2017, this topic was the focus of the first AREA-directed research project. The AREA published the first report on the topic of security for wearable AR displays to members in June 2017 and released the report and assessment protocol to the ecosystem in mid-2019.",Christine Perey,2021-08-31
37,Impact of AR Delivery in Human-Supported Operational Risk Mitigation,"Whilst automation continues to bring efficiency to operational processes and practices and IoT data capabilities increase exponentially, a crucial element around human intervention remains unaddressed. Specifically, as incoming data indicates that an operational process is trending upward or downward and is approaching deviation from set thresholds, are the humans in proximity to this equipment aware and can they proactively take decisions around appropriate actions, consulting additional support human support and/or schematics, flow charts, or other assets, where necessary? In 2018, McKinsey published an informative report on skill shifts, automation, and the future of the workforce, indicating that, while hours spent performing physical, manual, and basic cognitive skills would decrease by 14-15% between the years 2016 and 2030, higher cognitive skills, social and emotional skills, and technological skills would increase by 8, 24, and 55% respectively. This indicates a sharp departure from manual physical intervention and a transition to interaction between environmental data, people, and equipment in nuanced ways that involve rational analysis and resulting action. +

Increasingly, industries are collecting mass amounts of operational data and parameters via IoT dashboards, though there is little guidance that enables the operator of the future to interpret this data and take appropriate action proactively. Deloitte's 2020 Global Human Capital Trends report indicated that high performance organizations are “evolving from a focus on automating work to replace workers, to augmenting workers with technology to create superjobs, to collaborating with technology to form superteams”. AR is specifically and ideally positioned to play a large role in this transition process for organizations across the globe.

This study would aim to specifically measure the tangible operational processes proactively improved by human intervention to a process prompted by a connected AR headset, providing data insights, as well as prompting appropriate proactive human behavior to maintain operational parameters/limits. +

","Automation, resklling, skill development, augmentation, superjobs, superteams, operational excellence, IoT, process improvement, augmented reality, augmented reality, failure, indicators, just in time, mixed realities, optimization","Business, End User and User Experience, Use Cases, Displays","Operational excellence professionals, chief operating officers, board of directors, safety and risk professionals","- Automation introduces new workforce compositions and behaviors. In order to adapt, organizations will need to deploy AR for humans in the workforce that encourages higher-level cognitive processes and decision making, in partnership with automated technology and data at the worksite.
- As data analysis and technological literacy varies greatly among operational workforces globally, some degree of intervention and support will be necessary to ensure that productivity and safety targets are achieved in a new age of work.
- AR is uniquely positioned to deliver guidance and to develop workforce skills in the ""flow of work"", as it does not require hand-held or mounted displays that compromise safety and efficiency by directing human hands and eyes away from the production cycle itself.+","The proposed research would need to identify operational processes for which operational parameters/thresholds have been defined and IoT data is available. Research would include current % of time operational process performs outside of appropriate limits/thresholds and introduction of AR data presentation, analysis, and intervention via A/B trial scenarios, potentially with a few different levels of AR intervention. Observe post-intervention data. Post-study operational process optimization time could be calculated and recommendations developed for future implementation.",Near,"This study could be combined with existing research programs associated with metals and mining, oil and gas, aerospace, manufacturing, and operational excellence in general.","There are valuable references related to automation and necessary upskilling contained in https://www.mckinsey.com/featured-insights/future-of-work/skill-shift-automation-and-the-future-of-the-workforce[this report published by McKinsey.] https://www2.deloitte.com/us/en/insights/focus/technology-and-the-future-of-work/reskilling-the-workforce.html[This report published by Deloitte] focuses on guidance and learning ""in the flow of work.""",Jennifer Rogers,2021-08-31
38,Opportunities for AR Cloud Technologies in Enterprise,"AR Cloud technologies are emerging as part of a broader, 3D “spatial computing” trend. Accurate three-dimensional and spatially-anchored models of the real world are being captured using AR devices and proposed for the design of AR-enabled services with high fidelity positioning of users and assets to automatically connect workers with data from enterprise management systems. Proponents of AR Cloud architectures suggest that using these distributed technologies will result in lower total cost of ownership, higher performance and more flexible AR-enabled solutions. With spatial computing, AR users will have higher engagement, seamless collaborative experiences while sharing 3D models, and options for separating static from dynamic parts of the physical world in AR authoring. By securely off-load computational complexity of AR processes to the edge of their networks, AR display devices will be lighter, have lower power requirements and, potentially lower costs.

This research project will focus on definition of requirements and development of prototypes of devices and network technologies that are not tied to any single vendor's device and network offerings. The results will permit enterprises to evaluate and quantify the benefits of distributed AR Cloud architectures without limiting options for multi-vendor networks. Edge computing technologies will also be essential components.

","edge computing, spatial computing, AR cloud, cloud computing, 3D mapping, computer vision, object tracking, localization, relocalization, edge computing, cloud computing, distributed computing, network architecture",Technology,"Network operators, network managers, enterprise IT managers, AR display designers, AR display manufacturers, AR experience authoring platforms, AR developers","- Before introducing new architectures in their networks, AREA member organizations must understand the potential benefits and ensure that they are not locked into one vendor's vertically-integrated technology silo.
- AREA members need to better understand the potential risks and opportunities of introducing AR Cloud in enterprise networks.
- In addition, AREA members seek research that will develop practical guidelines and permit them to keep up with and evaluate this trend over the coming months and years.","The research will focus on edge computing technologies from multiple suppliers that can support distributed AR architectures. Studies will compare the components of AR experience delivery that are suited to distributed computing. Laboratory-based studies in controlled environments will measure performance characteristics across different scenarios. There will also need to be study of network-based storage of world maps and the use of these 3d models for real-time object identification, device and object tracking, and localization of devices and objects. End user satisfaction studies can also be used for this research.",Medium,"This research topic could be part of a program studying the potential benefits of 5G networks which provide low-latency and high bandwidth connectivity. Other topics such as cloud-based rendering of 3D graphics, discovery of AR experiences and security could be combined with this topic.",The study and testing of AR cloud technologies in enterprise use cases and networks was proposed as an AREA-directed research project topic in January 2021.,Christine Perey,2021-08-31
39,Safe and Secure Multi-User Wearable AR Display Management Systems,"Wearable AR displays are expensive to purchase and, once they are tested and configured for AR experiences in the enterprise, they are highly valuable, limited resources. One of the issues AR managers encounter when seeking funding to purchase wearable AR displays is that no single user needs to have the display for all their tasks during a shift. In fact, until many more AR experiences are published and accepted, display devices are in use for only a fraction of a work day.

In principle, different workplace roles could use the same AR display during different parts of a process or a shift, thereby distributing the fixed cost of the hardware across multiple users and procedures, and ensuring that the system is not idle for significant time.

This research topic focuses on development of solutions to address two issues that currently prevent wearable AR displays from serving as multi-user resources. The first challenge is an environmental health and safety issue. Unless procedures for cleaning AR displays are tested and proven to the workforce to be effective and safe for them, employees are uncomfortable using a shared personal device. Sensitivity to this issue is even greater since the emergence of Covid-19.

The second issue that presents a barrier is the extension of mobile device management (MDM) to AR displays. There must be easy-to-use, reliable, effective and secure authentication of users who share wearable AR displays. User authentication, without typing in user names and passwords, is required in order that the user wearing the AR display at any time receive only those work orders and information that match the employee's current work order, level of training and roles on the job site.

The scope of this research straddles two fields that are not easily combined. The two topics could be studied separately.

","sanitation, clean equipment, access control, user authentication, authorization, biometric, safe display cleaning,, safety, sanitation, access control, data protection, security systems,  authentication, message authentication, authorization","Displays, End User and User Experience, Technology","Workplace safety managers and officers, IT security managers, employees working in facilities driven by work orders, AR managers, AR experience developers, AR interface designers who would develop prompts and procedures for easy login","- Enterprises cannot purchase sufficient AR display hardware to have every employee have their own, personal device for a full shift.
- AREA members will be looking for ways to distribute display hardware across multiple users.
- They will need systems to reduce risk of contamination and transmission of skin or respiratory conditions between users.
- AREA members must provide a way for users to reliably, easily and quickly log into their personal account. Very little is known or documented about possible impacts of the issues around these topics.","This project will require laboratory or bench studies with different sanitation systems, then microbiological studies to determine effectiveness of different procedures. For the authentication and log in systems, development of biometric identification systems would be valuable. These could be compared with commercial log-in interfaces to manage user identification. Further, after the tests in laboratories, there should be research on the use of these approaches with end users for acceptance.",Near,This topic is closely related to another proposed AREA Research Agenda topic on end user biometric authentication for security purposes [Tauthentication5-biometric]. The topics could be combined with other AR security topics to develop a full research program.,"In July 2021, https://cyberbytesfoundation.org/news/cyber-bytes-foundation-announces-grant-award/[NIST’s Public Safety Communications Research Division has awarded a $1M grant to CyberBytes Foundation (CBF) and XR Saftey Initiative (XRSI)] to study feasibility and develop natural AR device user authentication methods that do not require users to perform specific actions (typing passwords, swiping ID cards). XRSI Privacy & Safety Framework will be used as a tool to assess natural AR Authentication methods by first responders and others working in public safety organizations.",Christine Perey,2021-08-31
40,Barriers to Adoption of AR-assisted Inspection for Quality and Compliance,"Real world conditions must be compared with the agreed or defined compliance targets in many industries. In the future, any discrepancies detected through machine learning or artificial intelligence algorithms trained on compliant samples, could automatically show those discrepancies to the user in AR view.

Inspection use cases are not as widely implemented as step-by-step instruction delivery (task guidance) remote assistance and training. Companies with AR deployments in other use case categories could increase their ROI on AR investments if they were to expand their support for AR-assisted inspections. Providers of technologies need greater insights into inspection requirements and industries that perform inspections before work continues or, for compliance purposes, require inspections to be documented.

","inspection, quality, safety, compliance, policy, use cases, quality control, quality management, inspection, defects, fault detection, measurement, nondestructive examination, nondestructive testing, process monitoring, product quality, quality assurance, testing","Industries, Use Cases","Business and production managers in any industry where inspections are performed for review and confirmation of meeting any quality and/or safety policies, Safety managers, compliance managers, quality managers","- Research in this area will permit effectively transferring or adapting existing AR procedures and technologies from existing use cases to AR-assisted inspection.
- This would leverage existing infrastructure investments and knowledge about AR implementation (increase AR ROI) and reduce time and costs of existing inspection processes to increase compliance and ability to document compliance in the workplace","Interviews with business and production managers in any industry where inspections are performed for review and confirmation of meeting any quality and/or safety policies, safety managers, compliance managers, quality managers will need to be conducted and their KPIs documented.

In parallel, existing ML or AI techniques will need to be extended or new data sets for training created for use with AR technologies for capture and vision-based objective analysis of real world conditions. When real world conditions diverge from the compliance goal, any discrepancies will automatically be presented to the user in AR view. Following development of test methodologies, results will be validated by compliance specialists. End user acceptance and user experience will also be studied through feedback from users in interviews and surveys following use of the inspection use case in controlled environments.",Medium,This topic or theme of research overlap with the topic of using AR for automatically detecting workplace safety compliance. Automatic assessments of the workplace could also provide alerts when supplies are needed or maintenance scheduled. The same research topic could be combined with study of user interfaces and interaction paradigms for emergency response use cases.,This topic was submitted for 9th AREA research projects and received high support.,Christine Perey,2021-08-31
41,"Visualization of Routes, Risks and Transit Time in AR","Efficient navigation between locations is a challenge encountered in many use cases. Routing and guidance to a location is a killer app for smartphones. Using context to help users navigate to their destinations will also be valuable for AR users but more research is needed to integrate real time data in route calculation and further study on user interfaces will also benefit this use case.

Traffic information from smart phone users contributes to calculations of routes for drivers. At a finer grain, real time data from captured video (e.g., on users and their devices) and stationary or mobile sensors could further improve route planning. Route planning could be made more efficient in workplaces and to remote locations. Visualizing routes and transit times in a wearable AR display permits the user to use both hands and avoids the user needing to look away from the objects and possible obstacles in the vicinity.

For example, in factories or warehouses, workers need to avoid moving through zones where robots are operating, where materials they are transporting do not fit through openings or through any space that is secure and requires credentials for entry/exit. Often the professional is expected to travel to a place which is unfamiliar/to which they have never been. Studies that train, with machine learning, algorithms to detect and use real world conditions would be highly beneficial. A professional may avoid unsafe or impassible routes.

","geospatial AR, GPS, global positioning system, location, position, orientation, route, route optimization, navigation, planning, guidance, routing, computerised navigation, global positioning system, navigation, navigation systems","Use Cases, End User and User Experience","Many use cases include the need for a user to walk or drive between locations. When conditions are apt to change between locations or the exact destination is new each time, an automatic, real-time and AR-enabled navigation support technology can ensure the most efficient and safest routes are followed. Visualization in AR removes the need to look at another device for route information. When small incremental improvements in efficiency are compounded over thousands of users, following optimized routes can impact workforce productivity and lower risk.","- AREA customer segment organizations have large workforces with diverse needs for movement.
- Reducing transit times while also increasing safety are ways to improve operational efficiencies.
- AR providers could integrate navigation support into other use cases, permitting the user to receive value from the wearable AR device investment between other stationary/non-mobile activities and use cases.","Visualizing route, risk and transit time in AR requires use of geospatial positioning and orientation and will build upon existing navigation technologies and extending technologies already in use (e.g., smart phones) in a variety of environmental conditions (e.g., low and bright light). Indoor navigation technologies (without use of GPS) can build upon use of beacons and other types of landmarks that can be detected using an AR-enabled device. Extensive user testing with diverse user interfaces is required to develop options that meet the needs of different use cases.",Medium,"Visualization of routes, risks and transit time is a use case based on real time data and AI, and can be combined with studies of AR-enhanced use cases, such as situational awareness and simulation. It also can be combined with research into and contributions to the field of technology for error and risk detection.","This topic has been studied in many dimensions and in conjunction with other services. In 2015, https://www.researchgate.net/publication/272760699_Location-Based_Augmented_Reality_Information_for_Bus_Route_Planning_System[a study demonstrated that AR could help users of public transportation by putting destinations and other information on municipal buses].

In March 2021, Google https://www.theverge.com/2021/3/30/22357528/google-maps-directions-indoor-ar-live-view-fuel-efficient-weather-air-quality-layer[announced that it would provide live AR view of route and guidance] using Google Maps for pedestrians in airports, transit stations, and malls.",Christine Perey,2021-08-31
42,Informing AR Users About Hazards in Proximity,"In many industries, workplaces contain a plethora of hazards. When known or anticipated, hazard management protocols reduce the risks associated with a user's encountering a hazard when performing tasks or fulfilling a work order. However, there are also hazards which, even if made aware of them, the user is untrained to treat or has insufficient time to avoid or deescalate. Alerts can provide the user time to react. On the other hand, there may be hazards that do not require any specific user actions.

Through data collected by user location sensing technologies on devices, and potentially on users' PPE, as well as maps of known hazards, data generated from sensors on stationary or moving machines, and other methods, artificial intelligence algorithms could be used to continuously maintain and monitor a dynamic 3D map of hazards in a user's proximity. The user may be provided the hazard proximity map at intervals or request to visualize hazards in proximity. When the user reaches conditions with respect to the hazard that suggests appropriate actions are needed, an alert on an AR device can spatially anchor the source of risk or hazard in the user's perception (see Automated Alert to Dangerous Settings [[ra-Salert5-dangerosity]]). If and when needed, guidance for risk mitigation can be provided.

","Hazard detection, hazard management protocol, hazard warning, location-detection, 3D spatial mapping, artificial intelligence, user interface, user experience, risk assessment, risk management, situational awareness, occupational risks, risk assessment, risk perception, accidents, occupational health, occupational safety, safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Industries, Technology, Business","Safety managers, workplace designers, risk managers",- This research will provide AREA members insights into the workplace of industrial employees and could furnish protocols to include in AR systems when integrating with enterprise safety and risk management systems.,"This research can include studying appropriate definitions of proximity and risk in diverse industries and workplaces and/or using existing risk management tools, capturing data sets and training algorithms for types of hazards and testing reliability of AI in diverse conditions. The study of user interface and user experience for hazard notification systems will contribute to this field. Further, user studies will be required to measure cognitive load and user responsiveness to notifications of hazardous or potentially hazardous circumstances.",Near,"The scope of this research can span many industries and workplaces. It could be tailored to any industry in which AR is introduced and demonstrated with many workplace use cases. It is closely related to other proposed topic concerned with Automated Alert to Dangerous Settings, and a topic focusing on dangers due to chemical or radiation in employee vicinity. It could be combined with research on visualization of IoT data streams, 3D maps of known risk and other safety management programs. Further, it also can include or be an extension of numerous 3D user interface and user experience topics.","This peer-reviewed article published in December 2015 entitled https://www.sciencedirect.com/science/article/abs/pii/S092658051500196X[""Proximity hazard indicator for workers-on-foot near miss interactions with construction equipment and geo-referenced hazard areas""] pertains to the topic of this research.",Christine Perey,2021-08-31
43,Operational Risk Categorization/Matrices as an Indicator of AR Impact Potential,"While it is widely believed that the use of AR has vast potential in operational contexts, particularly those in which large amounts of risk are present, it is thus far difficult for senior stakeholders to narrow down operational processes and scenarios that stand to receive the largest benefit from the introduction of AR technology. Being able to clearly define and target specific opportunities for not only significant process improvement, but also tangible reductions in Lost Time Incident Rate (LTIR) and Total Recordable Incident Rate (TRIR), due to safe and effective operations.  It is quite standard in high-risk, high-compliance industries to operate under what is typically called a Risk Appetite Matrix, which considers risk type, projected impact, and projected likelihood to determine risk appetite and inform specific mitigation strategies. Because this determination is a human one and involves a series of factors, AR may even prove helpful around remote collaboration/guidance to operators as they make these decisions. Furthermore, the assignment of AR as PPE to particular workplace operations prone to higher risk should clearly demonstrate ROI that would warrant scalable and wide-spread adoption worldwide.

","Operational risk, operational risk management, Lost Time Incident Rate, LTIR, Total Recordable Incident Rate, TRIR, safety, compliance, hazard identification, occupational risks, risk assessment, risk perception, accidents, occupational health, occupational safety, safety, health and safety, health hazards, safety devices, safety factor, safety systems, fault detection, monitoring, system monitoring","Industries, Technology, Business","Business and production managers, operational excellence personnel, and HSE professionals in high-risk, high-compliance industries and/or industries where risk tolerance must be low (e.g. aviation and aerospace, healthcare, oil and gas, metals and mining, manufacturing, etc.). It may be helpful to consider individuals in a position to expose the organization to financial, safety, health, environmental, legal or regulatory, social, or reputational risk.","- As LTIR and TRIR are recorded and reported to OSHA each year (in US), it is essential to maintain these statistics so as to ensure a balanced scorecard.
- These metrics are carefully scrutinized at the C-Suite level and substantial budget is provided to help sustain/improve these metrics.
- Identification of operational contexts with the lowest risk appetite subsequently identifies specific opportunities for tangible outcomes that may be delivered via AR intervention.
- This, in turn, can result in tangible ROI and scalability that stimulates further investment in the use of AR, and potentially even AR as a PPE mandate, in some operational processes and contexts worldwide.","Utilize existing organizational and/or industry risk appetite matrix to identify operational processes for which intervention is most likely to impact organizational scorecard (medium to significant). If possible, target across multiple industries, focusing on one specific type of operational risk (financial, safety, health, environmental, legal or regulatory, social, or reputational). +
Decide upon an operational process/context for which pre-intervention metrics (LTIR, TRIR) data is available and introduce AR intervention via A/B trial scenario. Observe post-intervention data. +
Translate observable LTIR, TRIR decreases into Cost Benefit Analysis for AR implementation for different risk ratings of different types. +
Subsequent projects could adapt existing AI algorithms to scrape Standard Operating Procedures to identify recommended processes for AR supplementation. +",Near,"This study could link closely with existing research programs associated with remote operations support and decision-making, as well as any programs around business impact and measures. Additionally, it is a fantastic candidate for studies looking at the utilization of Artificial Intelligence/Machine Learning and AI.","References related to risk appetite matrices include:
https://www.good-governance.org.uk/services/risk-appetite-for-nhs-organisations-a-matrix-to-support-better-risk-sensitivity-in-decision-taking/ +
http://broadleaf.com.au/resource-material/risk-appetite-is-using-this-concept-worth-the-risk/ +
https://ppl.app.uq.edu.au/content/1.80.01-enterprise-risk-management +
https://www.ior-institute.org/wp-content/uploads/2018/11/20180905-Developing-and-Implementing-Effective-OpRisk-Appetite-Framework.pdf +
References related to HSE scorecard metrics include:
http://www.csb.gov/userfiles/file/mackenzie%20presentation.pdf +
https://bscdesigner.com/safety-kpis.htm +
https://www.levitt-safety.com/blog/trif-trir-and-dart-whats-the-difference-and-why-do-they-matter/#:~:text=TRIR%20stands%20for%20Total%20Recordable,effectiveness%20of%20safety%20programs%2C%20and +",Jennifer Rogers,2021-08-31
44,Minimum Useful Fidelity of Streamed Large-scale 3D Models over 5G,"Large scale 3D models and point clouds play an important role in many fields ranging from simulation to Product Lifecycle Management to digital twins deployed on a plethora of AR-capable devices. However, due to systems or resource limitations, these models are not always as close to the reality as they purport to be.

Using AR connected to 5G networks, it is possible to stream these models to a device to assist processes performed by human operators or technicians. Generally speaking, the simpler the model (i.e. the lower the fidelity), the less resource is required for streaming. However, if simplification goes too far, utility suffers, possibly preventing the operator from performing the intended task.

The research scope should include comparative studies measuring the exact impact of automatic model and point cloud simplification due to streaming, possibly expressed by the decrease in polygon count vs the time required and error rates achieved in a particular operations. Measurement methods would be developed to ensure accuracy within 5% margin of error.

","point cloud, large-scale 3D models, polygons, low-poly, high-poly, realistic, surfaces, finite element method, computer simulation, digital simulation, computational mechanics, computer aided engineering, discrete event simulation, virtualization","Technology, Business","Operations leaders, financial management, OEM manufacturers, Independent Software Vendors, Cloud Service Providers","- Large-scale models play an increasingly important role across various verticals of interest and importance to AREA members, requiring the justification of the investment at one or more levels.
- AREA members will benefit from having ways to manage this investment by cross-optimizing model fidelity and utility delivering model quality that is fit for the purpose but not better.",This research project will make a statistically significant number of comparisons between versions of different fidelity of the same large-scale 3D model and point clouds and will examine their impact on the performance aided by said models. Examining the relationship between model fidelity and human performance will inform the investment process for large-scale 3D models. New methods could be developed to compare usefulness at different levels of fidelity in various industries to clarify why some industries require different levels of fidelity to meet their objectives.,Medium,This research topic can be combined with other projects examining the tradeoffs between fidelity and function of large-scale 3D models.,Several AREA members are already working in this field and the 7th AREA research project performed a comparison of commercial solutions available for model decimation although did not study the streaming aspect of this research topic. The MxD is interested in collaborating to use its mmWave 5G infrastructure in a factory setting to study this topic further.,Peter Orban,2021-08-31
45,Rapid QA of Forensics and Public Safety 3D Scanning Outputs,"Accurately capturing accident, crime or crash scenes, and other scenes relevant from a Public Safety standpoint is of utmost importance for law enforcement or other government agencies. This tedious and error-prone work has tremendously benefitted from the adoption of laser scanners made by OEMs like Faro, Leica and others.

Deploying laser scanners to capture crime scenes and other relevant real world situations generates a complex point clouds which requires extensive post processing before the final models are constructed – a process that takes place offsite after scanning. Therefore, potential errors of over or under scanning - which can significantly deteriorate the quality of the model – is difficult to detect on location. This is of particular concern when the use of scanning equipment is not frequent, e.g. a small town police department or large-scale disaster event.

By deploying AR glasses it is possible to track the location of the scanning device and combine it with its effective scanning range at every stage to create a visual representation of the scanning footprint. This could yield an effective “coverage map” visible via smart glasses that would help the operator spot under-scanned areas. This topic includes a detailed examination of scanning footprint detected via smart glasses, in comparison to the 3D scene captured by the actual point cloud.

","point cloud, laser scanning, disaster scene, crime scene, law enforcement, 3d models, point clouds, digital twin","Technology, Business","Public safety agencies such as police crime scene investigators, law enforcement, FEMA, OEM manufacturers. If techniques are widely published, Independent Software Vendors could integrate the capability as a new feature in their existing applications and support more devices.","- Laser scanning plays an important role in preserving the physical reality in a digital format, which in turn can inform critical legal decisions or strategic plans. However, any error in the scanning process could significantly deteriorate its utility or render it completely useless.
- It is important to ascertain the quality of a scan even before the point cloud itself gets processed offsite.

The AREA members need ways to validate, when creating point clouds, that investing in using spatial tracking (as a proxy for point cloud quality) delivers an appropriate result in eliminating scanning errors.
",This research project will make a statistically-significant number of comparisons between point clouds and their respective scanner location tracking information of the same site with the purpose of creating a regression model that accounts for measurement errors in the independent variables.,Medium,This research topic can be combined with other projects examining the tradeoffs between fidelity and function of large-scale 3D models.,There's an ISMAR 2019 paper about how to use AR device to track the viewpoint of the scanner to ensure that an object is fully scanned in 3D. This research topic could be an extension to the prior published research.,Peter Orban,2021-08-31
46,Multi-layered Approach to Public Asset Utilization in Smart Cities,"There is a wide range of assets in urban environments: public spaces, buildings, concentrations of demography, utilities, history, movement of people and objects and so on. These assets carry significant value for all those interacting with them but the nature and manifestation of the value depends on the context and the use case.

The nature of value associated with the same asset depends on the nature of the interaction: occupancy for a realtor, history for a tourist, compliance for the Code Enforcement employee and so on – all built around the same digital twin of the host city.

Following proper authorization, head mounted displays or handheld devices can unlock the value contained in an asset, guiding and enhancing the interactions of a user with a city and its inhabitants.

This research topic also includes architecting a multipurpose Digital Twin of a set of assets, associating them with various layers of value and examining modalities of consumption from a human factors perspective.

","public asset management, public services, scanning, smart cities, urbanization, intelligent buildings, urban growth, town and country planning, urban planning, digital twin, smart cities, street lighting","Technology, Business","Elected and professional urban leaders: Mayors, CIOs and CISOs of urban infrastructure, Independent Software Vendors, geospatial infrastructure providers, points of interest publishers","- According to the UN, 68% of the world population projected to live in urban areas by 2050. This will put an increased strain on most public assets to optimizing how to unlock their value will be critical for resident quality of life and visitor experiences.
- Best practices developed in urban design, information architecture and human factors will be extended by the results of this research.",This research will require scanning and associating data with urban assets and developing methodologies to test different use cases and scenarios. User satisfaction and productivity studies in field trials will contribute to development of best practices for specific industries.,Long,This topic is a good fit with most topics focused on Smart Cities and long-range outdoor positioning.,"The UN has published https://www.un.org/development/desa/en/news/population/2018-revision-of-world-urbanization-prospects.html#:~:text=News-,68%25%20of%20the%20world%20population%20projected%20to%20live%20in,areas%20by%202050%2C%20says%20UN&text=Today%2C%2055%25%20of%20the%20world's,increase%20to%2068%25%20by%202050[reports about urbanization and the challenges it raises for those managing urban data].",Peter Orban,2021-08-31
